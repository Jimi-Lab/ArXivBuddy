# Daily arXiv Papers
## Date: 2025-07-26
## Description: 用户自定义提示词：

AI

Zotero文献库分析：
### 主要研究方向
该用户的研究方向主要集中在**软件安全与人工智能的交叉领域**，核心关注点包括：
1. **漏洞检测与防御**：尤其关注深度学习（如Transformer、图神经网络）在静态/动态漏洞检测中的应用（如DeepDFA、DeepWukong、LineVul），以及大语言模型（LLM）在漏洞检测中的潜力（如GPT-4在漏洞检测中的表现）。
2. **大语言模型（LLM）安全**：研究LLM在代码分析、模糊测试、漏洞检测中的能力与局限性（如CodeBERT、LLM驱动的模糊测试），同时关注LLM的安全风险（如提示注入攻击、模型劫持、对抗样本生成）。
3. **AI驱动的攻击与防御**：探索AI模型（如深度学习、LLM）在网络安全中的双向应用，包括攻击（如对抗样本生成、模型后门）和防御（如联邦学习中的隐私保护、鲁棒性增强）。

---

### 感兴趣领域
1. **代码分析与程序理解**：
   - 预训练模型（如CodeBERT）在代码-自然语言双模态任务中的应用。
   - 二进制代码分析（如WebAssembly反编译、二进制代码相似性检测）。
   - 静态程序分析的并行化与中间表示（IR）优化。
2. **AI安全与对抗攻防**：
   - LLM的提示注入攻击（如HOUYI攻击框架）及防御（如设计模式、知识增强的代理框架CRAKEN）。
   - 模型后门攻击（如Imperio语言引导的后门）与防御（如联邦学习中的水印去除Sanitizer）。
   - 多模态系统的对抗攻击（如图像、文本、音频的联合攻击）。
3. **实际系统安全**：
   - 物联网（IoT）生态的LLM威胁检测框架。
   - 微服务架构中的污点分析（如MScan工具）。
   - 区块链欺诈检测的高效语言模型训练（如ZipZap框架）。

---

### 代表性主题
1. **漏洞检测的深度学习方法**：
   - 结合数据流分析与图神经网络（DeepDFA）提升检测效率。
   - 多基单元漏洞（MBU）对检测准确性的影响及改进框架。
   - LLM在漏洞检测中的零样本/小样本能力（如GPT-4超越传统方法）。
2. **LLM安全与代理通信**：
   - LLM代理通信协议（如MCP、A2A）的安全风险与防御。
   - 知识增强的LLM代理（如CRAKEN）在CTF挑战中的应用。
   - 针对LLM集成的红队测试经验（如100个生成式AI产品的对抗测试）。
3. **鲁棒性与隐私保护**：
   - 联邦学习中的高效隐私攻击（EPAFL）与防御（如无害水印）。
   - 个性化隐私保护掩码（P3-Mask）对抗非授权人脸识别。
   - 图神经网络（GNN）后门攻击与图缩减技术的鲁棒性分析。

---

### 常用方法
1. **深度学习与图模型**：
   - Transformer架构（如CodeBERT、基于注意力的模型）和GNN（如DeepWukong）用于代码表示与漏洞检测。
   - 对比学习（如BinCola）提升二进制代码相似性检测的跨域泛化能力。
2. **对抗攻防技术**：
   - 黑盒攻击（如HOUYI）与自适应防御（如STDLens对抗模型劫持）。
   - 集成学习（如FUSE）通过多样性增强检测鲁棒性。
3. **数据驱动优化**：
   - 基于LLM的漏洞样本生成（GVI）解决类别不平衡问题。
   - 轻量级模型压缩（如ZipZap的频率感知压缩）提升训练效率。
4. **静态与动态分析结合**：
   - 混合静态分析（如MScan的污点分析）与动态模糊测试（如LLM驱动的模糊测试）。

---

### 总结
该用户的研究具有鲜明的**跨学科特色**，聚焦于AI技术与软件安全的深度融合，核心目标是提升漏洞检测的自动化能力、增强AI模型的安全性，并探索实际系统中的攻防博弈。其工作兼顾理论创新（如新型鲁棒性指标、知识增强框架）与工程实践（如工具开发、红队测试），同时关注前沿挑战（如LLM代理通信安全、多模态攻击面）。未来可能进一步探索**AI驱动的自动化安全运维**和**可解释的AI安全分析**。

## Papers:
### 1. Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory
#### Abstract:
While large language models (LLMs) leverage both knowledge and reasoning during inference, the capacity to distinguish between them plays a pivotal role in model analysis, interpretability, and development. Inspired by dual-system cognitive theory, we propose a cognition attribution framework to decouple the contribution of knowledge and reasoning. In particular, the cognition of LLMs is decomposed into two distinct yet complementary phases: knowledge retrieval (Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs are prompted to generate answers under two different cognitive modes, fast thinking and slow thinking, respectively. The performance under different cognitive modes is analyzed to quantify the contribution of knowledge and reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results reveal: (1) reasoning adjustment is domain-specific, benefiting reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and potentially imparing knowledge-intensive domains. (2) Parameter scaling improves both knowledge and reasoning, with knowledge improvements being more pronounced. Additionally, parameter scaling make LLMs reasoning significantly more prudent, while moderately more intelligent. (3) Knowledge primarily resides in lower network layers, while reasoning operates in higher layers. Our framework not only helps understand LLMs from a "decoupling" perspective, but also provides new insights into existing research, including scaling laws, hierarchical knowledge editing, and limitations of small-model reasoning.
#### Summary:
The paper proposes a cognition attribution framework inspired by dual-system cognitive theory to decouple the contributions of knowledge and reasoning in LLMs. It decomposes LLM cognition into knowledge retrieval (Phase 1) and reasoning adjustment (Phase 2), analyzing performance under fast and slow thinking modes. The framework is applied to 15 LLMs across 3 datasets, revealing insights such as domain-specific reasoning adjustment, the impact of parameter scaling, and the layer-wise distribution of knowledge and reasoning. The study provides a 'decoupling' perspective to understand LLMs and offers insights into scaling laws, knowledge editing, and small-model reasoning limitations.
#### Relevance Score: 7.0
#### PDF URL: https://arxiv.org/pdf/2507.18178

### 2. AlphaGo Moment for Model Architecture Discovery
#### Abstract:
While AI systems demonstrate exponentially improving capabilities, the pace of AI research itself remains linearly bounded by human cognitive capacity, creating an increasingly severe development bottleneck. We present ASI-Arch, the first demonstration of Artificial Superintelligence for AI research (ASI4AI) in the critical domain of neural architecture discovery--a fully autonomous system that shatters this fundamental constraint by enabling AI to conduct its own architectural innovation. Moving beyond traditional Neural Architecture Search (NAS), which is fundamentally limited to exploring human-defined spaces, we introduce a paradigm shift from automated optimization to automated innovation. ASI-Arch can conduct end-to-end scientific research in the domain of architecture discovery, autonomously hypothesizing novel architectural concepts, implementing them as executable code, training and empirically validating their performance through rigorous experimentation and past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000 GPU hours, culminating in the discovery of 106 innovative, state-of-the-art (SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed unexpected strategic insights invisible to human players, our AI-discovered architectures demonstrate emergent design principles that systematically surpass human-designed baselines and illuminate previously unknown pathways for architectural innovation. Crucially, we establish the first empirical scaling law for scientific discovery itself--demonstrating that architectural breakthroughs can be scaled computationally, transforming research progress from a human-limited to a computation-scalable process. We provide comprehensive analysis of the emergent design patterns and autonomous research capabilities that enabled these breakthroughs, establishing a blueprint for self-accelerating AI systems.
#### Summary:
The paper introduces ASI-Arch, an autonomous AI system designed to discover novel neural architectures, moving beyond traditional Neural Architecture Search (NAS) by enabling AI to conduct its own architectural innovation. ASI-Arch autonomously hypothesizes, implements, trains, and validates new architectures, leading to the discovery of 106 state-of-the-art linear attention architectures. The system demonstrates emergent design principles that surpass human-designed baselines and establishes a scaling law for scientific discovery, transforming research progress into a computation-scalable process.
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18074

### 3. Logical Characterizations of GNNs with Mean Aggregation
#### Abstract:
We study the expressive power of graph neural networks (GNNs) with mean as the aggregation function. In the non-uniform setting, we show that such GNNs have exactly the same expressive power as ratio modal logic, which has modal operators expressing that at least a certain ratio of the successors of a vertex satisfies a specified property. The non-uniform expressive power of mean GNNs is thus higher than that of GNNs with max aggregation, but lower than for sum aggregation--the latter are characterized by modal logic and graded modal logic, respectively. In the uniform setting, we show that the expressive power relative to MSO is exactly that of alternation-free modal logic, under the natural assumptions that combination functions are continuous and classification functions are thresholds. This implies that, relative to MSO and in the uniform setting, mean GNNs are strictly less expressive than sum GNNs and max GNNs. When any of the assumptions is dropped, the expressive power increases.
#### Summary:
The paper investigates the expressive power of graph neural networks (GNNs) using mean aggregation, comparing it to other aggregation functions like max and sum. It shows that mean GNNs are characterized by ratio modal logic in the non-uniform setting, offering higher expressiveness than max GNNs but lower than sum GNNs. In the uniform setting, mean GNNs are less expressive than both sum and max GNNs relative to MSO, under certain assumptions. The study highlights the theoretical limits and comparative strengths of mean GNNs in graph representation.
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18145

### 4. Revisiting LLM Reasoning via Information Bottleneck
#### Abstract:
Large language models (LLMs) have recently demonstrated remarkable progress in reasoning capabilities through reinforcement learning with verifiable rewards (RLVR). By leveraging simple rule-based rewards, RL effectively incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning trajectories, progressively guiding them toward correct answers. However, existing approaches remain largely heuristic and intuition-driven, limiting the development of principled methodologies. In this paper, we present a theoretical characterization of LLM reasoning grounded in information bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO), a framework that encourages reasoning trajectories to be both informative about the final correct answer and generalizable across diverse prompts. We derive a practical token-level surrogate objective and propose an efficient approximation, resulting in the lightweight IB regularization method. This technique integrates seamlessly into existing RL-based post-training frameworks without additional computational overhead, requiring only a one-line code modification. Empirically, we validate IB regularization across multiple mathematical reasoning benchmarks and RL algorithms, demonstrating consistent improvements in LLM reasoning performance.
#### Summary:
The paper proposes a theoretical framework for LLM reasoning based on the information bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO). It aims to make reasoning trajectories informative about the correct answer and generalizable across prompts. The authors derive a token-level surrogate objective and propose a lightweight IB regularization method, which integrates into existing RL-based post-training frameworks with minimal overhead. Empirical validation shows improved LLM reasoning performance across mathematical benchmarks.
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18391

### 5. SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law
#### Abstract:
We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha' moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI.
#### Summary:
The paper introduces SafeWork-R1, a multimodal reasoning model developed using the SafeLadder framework, which focuses on coevolving AI capabilities and safety through progressive, safety-oriented reinforcement learning and multi-principled verifiers. It achieves significant improvements in safety benchmarks without compromising general capabilities and includes inference-time intervention methods for reliability. The framework's generalizability is demonstrated across multiple models.
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18576

### 6. I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis
#### Abstract:
Recent advances in agentic systems for data analysis have emphasized automation of insight generation through multi-agent frameworks, and orchestration layers. While these systems effectively manage tasks like query translation, data transformation, and visualization, they often overlook the structured reasoning process underlying analytical thinking. Reasoning large language models (LLMs) used for multi-step problem solving are trained as general-purpose problem solvers. As a result, their reasoning or thinking steps do not adhere to fixed processes for specific tasks. Real-world data analysis requires a consistent cognitive workflow: interpreting vague goals, grounding them in contextual knowledge, constructing abstract plans, and adapting execution based on intermediate outcomes. We introduce I2I-STRADA (Information-to-Insight via Structured Reasoning Agent for Data Analysis), an agentic architecture designed to formalize this reasoning process. I2I-STRADA focuses on modeling how analysis unfolds via modular sub-tasks that reflect the cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench benchmarks show that I2I-STRADA outperforms prior systems in planning coherence and insight alignment, highlighting the importance of structured cognitive workflows in agent design for data analysis.
#### Summary:
The paper introduces I2I-STRADA, an agentic architecture designed to formalize structured reasoning in data analysis. It addresses the gap in current multi-agent frameworks by modeling cognitive workflows through modular sub-tasks, improving planning coherence and insight alignment. Evaluations on benchmarks demonstrate its superiority over prior systems.
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.17874

### 7. SMARTAPS: Tool-augmented LLMs for Operations Management
#### Abstract:
Large language models (LLMs) present intriguing opportunities to enhance user interaction with traditional algorithms and tools in real-world applications. An advanced planning system (APS) is a sophisticated software that leverages optimization to help operations planners create, interpret, and modify an operational plan. While highly beneficial, many customers are priced out of using an APS due to the ongoing costs of consultants responsible for customization and maintenance. To address the need for a more accessible APS expressed by supply chain planners, we present SmartAPS, a conversational system built on a tool-augmented LLM. Our system provides operations planners with an intuitive natural language chat interface, allowing them to query information, perform counterfactual reasoning, receive recommendations, and execute scenario analysis to better manage their operation. A short video demonstrating the system has been released: this https URL
#### Summary:
The paper introduces SmartAPS, a conversational system built on a tool-augmented large language model (LLM) designed to enhance operations management. It provides an intuitive natural language interface for operations planners to query information, perform counterfactual reasoning, receive recommendations, and execute scenario analysis, making advanced planning systems (APS) more accessible without the need for costly consultants.
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.17927

### 8. Agentic AI framework for End-to-End Medical Data Inference
#### Abstract:
Building and deploying machine learning solutions in healthcare remains expensive and labor-intensive due to fragmented preprocessing workflows, model compatibility issues, and stringent data privacy constraints. In this work, we introduce an Agentic AI framework that automates the entire clinical data pipeline, from ingestion to inference, through a system of modular, task-specific agents. These agents handle both structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing recommendation without manual intervention. We evaluate the system on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging. For example, in the case of structured data (anxiety data) and unstructured data (colonoscopy polyps data), the pipeline begins with file-type detection by the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring privacy compliance, where we first identify the data type and then anonymize it. The Feature Extraction Agent identifies features using an embedding-based approach for tabular data, extracting all column names, and a multi-stage MedGemma-based approach for image data, which infers modality and disease name. These features guide the Model-Data Feature Matcher Agent in selecting the best-fit model from a curated repository. The Preprocessing Recommender Agent and Preprocessing Implementor Agent then apply tailored preprocessing based on data type and model requirements. Finally, the ``Model Inference Agent" runs the selected model on the uploaded data and generates interpretable outputs using tools like SHAP, LIME, and DETR attention maps. By automating these high-friction stages of the ML lifecycle, the proposed framework reduces the need for repeated expert intervention, offering a scalable, cost-efficient pathway for operationalizing AI in clinical environments.
#### Summary:
The paper introduces an Agentic AI framework designed to automate the entire clinical data pipeline, from ingestion to inference, using modular, task-specific agents. These agents handle structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing without manual intervention. The framework is evaluated on publicly available datasets in geriatrics, palliative care, and colonoscopy imaging, demonstrating its ability to reduce expert intervention and operationalize AI in clinical environments.
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18115

### 9. Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios
#### Abstract:
Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step logic. In finance, however, professionals must not only converge on optimal decisions but also generate creative, plausible futures under uncertainty. We introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent thinking in LLMs for financial tasks.
ConDiFi features 607 macro-financial prompts for divergent reasoning and 990 multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we evaluated 14 leading models and uncovered striking differences. Despite high fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models like DeepSeek-R1 and Cohere Command R+ rank among the top for generating actionable, insights suitable for investment decisions. ConDiFi provides a new perspective to assess reasoning capabilities essential to safe and strategic deployment of LLMs in finance.
#### Summary:
The paper introduces ConDiFi, a benchmark for evaluating both divergent (creative) and convergent (logical) thinking in LLMs for financial scenarios. It tests 14 leading models, revealing performance differences, with GPT-4o underperforming in novelty and actionability, while models like DeepSeek-R1 and Cohere Command R+ excel in generating actionable insights for investment decisions.
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18368

### 10. ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics
#### Abstract:
Unlike conventional Machine-Learning (ML) approaches, often criticized as "black boxes", Symbolic Regression (SR) stands out as a powerful tool for revealing interpretable mathematical relationships in complex physical systems, requiring no a priori assumptions about models' structures. Motivated by the recognition that, in fluid mechanics, an understanding of the underlying flow physics is as crucial as accurate prediction, this study applies SR to model a fundamental three-dimensional (3D) incompressible flow in a rectangular channel, focusing on the (axial) velocity and pressure fields under laminar conditions. By employing the PySR library, compact symbolic equations were derived directly from numerical simulation data, revealing key characteristics of the flow dynamics. These equations not only approximate the parabolic velocity profile and pressure drop observed in the studied fluid flow, but also perfectly coincide with analytical solutions from the literature. Furthermore, we propose an innovative approach that integrates SR with the knowledge-representation framework of Answer Set Programming (ASP), combining the generative power of SR with the declarative reasoning strengths of ASP. The proposed hybrid SR/ASP framework ensures that the SR-generated symbolic expressions are not only statistically accurate, but also physically plausible, adhering to domain-specific principles. Overall, the study highlights two key contributions: SR's ability to simplify complex flow behaviours into concise, interpretable equations, and the potential of knowledge-representation approaches to improve the reliability and alignment of data-driven SR models with domain principles. Insights from the examined 3D channel flow pave the way for integrating such hybrid approaches into efficient frameworks, [...] where explainable predictions and real-time data analysis are crucial.
#### Summary:
The paper presents a study on Symbolic Regression (SR) applied to fluid mechanics, specifically modeling a 3D incompressible flow in a rectangular channel. It highlights SR's ability to derive interpretable mathematical relationships from numerical simulation data, matching analytical solutions. The study also introduces a hybrid SR/Answer Set Programming (ASP) framework to ensure the derived equations are both statistically accurate and physically plausible. Key contributions include SR's simplification of complex flow behaviors into interpretable equations and the potential of knowledge-representation approaches to enhance data-driven models.
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.17777

### 11. E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI
#### Abstract:
How can AI move beyond imitation toward genuine creativity? This paper proposes the E.A.R.T.H. framework, a five-stage generative pipeline that transforms model-generated errors into creative assets through Error generation, Amplification, Refine selection, Transform, and Harness feedback. Drawing on cognitive science and generative modeling, we posit that "creative potential hides in failure" and operationalize this via structured prompts, semantic scoring, and human-in-the-loop evaluation. Implemented using LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the pipeline employs a composite reward function based on novelty, surprise, and relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to 1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4% improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a 4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment (CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones (3.99). Feedback highlights stylistic precision and emotional resonance. These results demonstrate that error-centered, feedback-driven generation enhances creativity, offering a scalable path toward self-evolving, human-aligned creative AI.
#### Summary:
The paper introduces the E.A.R.T.H. framework, a five-stage generative pipeline that leverages model-generated errors to foster creativity in AI. It involves Error generation, Amplification, Refine selection, Transform, and Harness feedback, utilizing tools like LLaMA-2-7B-Chat, SBERT, and Stable Diffusion. The framework demonstrates significant improvements in creativity metrics, novelty, and relevance, supported by human evaluations.
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18004

### 12. Does visualization help AI understand data?
#### Abstract:
Charts and graphs help people analyze data, but can they also be useful to AI systems? To investigate this question, we perform a series of experiments with two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three representative analysis tasks, the two systems describe synthetic datasets more precisely and accurately when raw data is accompanied by a scatterplot, especially as datasets grow in complexity. Comparison with two baselines -- providing a blank chart and a chart with mismatched data -- shows that the improved performance is due to the content of the charts. Our results are initial evidence that AI systems, like humans, can benefit from visualization.
#### Summary:
The paper investigates whether visualizations like charts and graphs can aid AI systems, specifically vision-language models (GPT 4.1 and Claude 3.5), in understanding and analyzing data. Experiments show that these models perform better in describing synthetic datasets when raw data is accompanied by a scatterplot, especially for complex datasets. The improvement is attributed to the content of the charts, as demonstrated by comparisons with baselines (blank or mismatched charts). The findings suggest that AI systems, like humans, can benefit from visualizations.
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18022

### 13. Multi-Agent Guided Policy Optimization
#### Abstract:
Due to practical constraints such as partial observability and limited communication, Centralized Training with Decentralized Execution (CTDE) has become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning (MARL). However, existing CTDE methods often underutilize centralized training or lack theoretical guarantees. We propose Multi-Agent Guided Policy Optimization (MAGPO), a novel framework that better leverages centralized training by integrating centralized guidance with decentralized execution. MAGPO uses an auto-regressive joint policy for scalable, coordinated exploration and explicitly aligns it with decentralized policies to ensure deployability under partial observability. We provide theoretical guarantees of monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across 6 diverse environments. Results show that MAGPO consistently outperforms strong CTDE baselines and matches or surpasses fully centralized approaches, offering a principled and practical solution for decentralized multi-agent learning. Our code and experimental data can be found in this https URL.
#### Summary:
The paper introduces Multi-Agent Guided Policy Optimization (MAGPO), a novel framework for cooperative Multi-Agent Reinforcement Learning (MARL) under the Centralized Training with Decentralized Execution (CTDE) paradigm. MAGPO leverages centralized guidance during training to improve coordination and exploration while ensuring deployability under partial observability. It provides theoretical guarantees of monotonic policy improvement and demonstrates superior performance across 43 tasks in 6 environments compared to existing CTDE methods and fully centralized approaches.
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18059

### 14. Foundations for Risk Assessment of AI in Protecting Fundamental Rights
#### Abstract:
This chapter introduces a conceptual framework for qualitative risk assessment of AI, particularly in the context of the EU AI Act. The framework addresses the complexities of legal compliance and fundamental rights protection by itegrating definitional balancing and defeasible reasoning. Definitional balancing employs proportionality analysis to resolve conflicts between competing rights, while defeasible reasoning accommodates the dynamic nature of legal decision-making. Our approach stresses the need for an analysis of AI deployment scenarios and for identifying potential legal violations and multi-layered impacts on fundamental rights. On the basis of this analysis, we provide philosophical foundations for a logical account of AI risk analysis. In particular, we consider the basic building blocks for conceptually grasping the interaction between AI deployment scenarios and fundamental rights, incorporating in defeasible reasoning definitional balancing and arguments about the contextual promotion or demotion of rights. This layered approach allows for more operative models of assessment of both high-risk AI systems and General Purpose AI (GPAI) systems, emphasizing the broader applicability of the latter. Future work aims to develop a formal model and effective algorithms to enhance AI risk assessment, bridging theoretical insights with practical applications to support responsible AI governance.
#### Summary:
The paper presents a conceptual framework for qualitative risk assessment of AI, focusing on compliance with the EU AI Act and protection of fundamental rights. It integrates definitional balancing (proportionality analysis) and defeasible reasoning to address legal complexities and dynamic decision-making. The framework analyzes AI deployment scenarios, identifies potential legal violations, and assesses multi-layered impacts on rights. It aims to provide philosophical foundations for AI risk analysis and future development of formal models and algorithms to support responsible AI governance.
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18290

### 15. The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams
#### Abstract:
We present our method for automatically marking Physics exams. The marking problem consists in assessing typed student answers for correctness with respect to a ground truth solution. This is a challenging problem that we seek to tackle using a combination of a computer algebra system, an SMT solver and a term rewriting system. A Large Language Model is used to interpret and remove errors from student responses and rewrite these in a machine readable format. Once formalized and language-aligned, the next step then consists in applying automated reasoning techniques for assessing student solution correctness. We consider two methods of automated theorem proving: off-the-shelf SMT solving and term rewriting systems tailored for physics problems involving trigonometric expressions. The development of the term rewrite system and establishing termination and confluence properties was not trivial, and we describe it in some detail in the paper. We evaluate our system on a rich pool of over 1500 real-world student exam responses from the 2023 Australian Physics Olympiad.
#### Summary:
The paper presents a method for automatically marking Physics exams by assessing typed student answers against a ground truth solution. It combines a computer algebra system, an SMT solver, and a term rewriting system, with a Large Language Model (LLM) used to interpret and reformat student responses. The system evaluates correctness using automated theorem proving techniques, including SMT solving and a custom term rewriting system for trigonometric expressions. The method was tested on over 1500 real-world student exam responses.
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18337

### 16. On the Performance of Concept Probing: The Influence of the Data (Extended Version)
#### Abstract:
Concept probing has recently garnered increasing interest as a way to help interpret artificial neural networks, dealing both with their typically large size and their subsymbolic nature, which ultimately renders them unfeasible for direct human interpretation. Concept probing works by training additional classifiers to map the internal representations of a model into human-defined concepts of interest, thus allowing humans to peek inside artificial neural networks. Research on concept probing has mainly focused on the model being probed or the probing model itself, paying limited attention to the data required to train such probing models. In this paper, we address this gap. Focusing on concept probing in the context of image classification tasks, we investigate the effect of the data used to train probing models on their performance. We also make available concept labels for two widely used datasets.
#### Summary:
The paper investigates the performance of concept probing, a method to interpret artificial neural networks by mapping their internal representations to human-defined concepts. It focuses on the influence of the data used to train probing models, particularly in image classification tasks, and provides concept labels for two widely used datasets.
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18550

### 17. Synthesis of timeline-based planning strategies avoiding determinization
#### Abstract:
Qualitative timeline-based planning models domains as sets of independent, but
interacting, components whose behaviors over time, the timelines, are governed
by sets of qualitative temporal constraints (ordering relations), called
synchronization rules.
Its plan-existence problem has been shown to be PSPACE-complete; in
particular, PSPACE-membership has been proved via reduction to the
nonemptiness problem for nondeterministic finite automata.
However, nondeterministic automata cannot be directly used to synthesize
planning strategies as a costly determinization step is needed.
In this paper, we identify a fragment of qualitative timeline-based planning
whose plan-existence problem can be directly mapped into the nonemptiness
problem of deterministic finite automata, which can then
synthesize strategies.
In addition, we identify a maximal subset of Allen's relations that fits into
such a deterministic fragment.
#### Summary:
The paper introduces a fragment of qualitative timeline-based planning that can be mapped directly to the nonemptiness problem of deterministic finite automata (DFA), enabling strategy synthesis without costly determinization. It also identifies a maximal subset of Allen's relations compatible with this deterministic fragment.
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.17988

### 18. Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes
#### Abstract:
The rapid development of COVID-19 vaccines has showcased the global communitys ability to combat infectious diseases. However, the need for post-licensure surveillance systems has grown due to the limited window for safety data collection in clinical trials and early widespread implementation. This study aims to employ Natural Language Processing techniques and Active Learning to rapidly develop a classifier that detects potential vaccine safety issues from emergency department notes. ED triage notes, containing expert, succinct vital patient information at the point of entry to health systems, can significantly contribute to timely vaccine safety signal surveillance. While keyword-based classification can be effective, it may yield false positives and demand extensive keyword modifications. This is exacerbated by the infrequency of vaccination-related ED presentations and their similarity to other reasons for ED visits. NLP offers a more accurate and efficient alternative, albeit requiring annotated data, which is often scarce in the medical field. Active learning optimizes the annotation process and the quality of annotated data, which can result in faster model implementation and improved model performance. This work combines active learning, data augmentation, and active learning and evaluation techniques to create a classifier that is used to enhance vaccine safety surveillance from ED triage notes.
#### Summary:
This paper focuses on using Natural Language Processing (NLP) and Active Learning to develop a classifier for detecting potential vaccine safety issues from emergency department (ED) triage notes. The study addresses the challenges of limited safety data collection in clinical trials and the need for post-licensure surveillance systems. The proposed approach combines active learning, data augmentation, and evaluation techniques to improve the accuracy and efficiency of vaccine safety signal detection from ED notes, which are often sparse and similar to other ED visit reasons.
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18123

### 19. Comparing Non-minimal Semantics for Disjunction in Answer Set Programming
#### Abstract:
In this paper, we compare four different semantics for disjunction in Answer Set Programming that, unlike stable models, do not adhere to the principle of model minimality. Two of these approaches, Cabalar and Muñiz' \emph{Justified Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly provide an alternative non-minimal semantics for disjunction. The other two, Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference} (DI) semantics, actually introduce a new disjunction connective, but are compared here as if they constituted new semantics for the standard disjunction operator. We are able to prove that three of these approaches (Forks, Justified Models and a reasonable relaxation of the DI semantics) actually coincide, constituting a common single approach under different definitions. Moreover, this common semantics always provides a superset of the stable models of a program (in fact, modulo any context) and is strictly stronger than the fourth approach (Strongly Supported Models), that actually treats disjunctions as in classical logic.
#### Summary:
This paper compares four non-minimal semantics for disjunction in Answer Set Programming (ASP), focusing on alternatives to stable models that do not adhere to model minimality. It examines Justified Models, Strongly Supported Models, Forks, and Determining Inference (DI) semantics, proving that three of these approaches (Forks, Justified Models, and a relaxed DI semantics) coincide, forming a common semantics that is a superset of stable models and stronger than Strongly Supported Models, which treats disjunctions classically.
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18198

### 20. Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation
#### Abstract:
This paper investigates the application of Reinforcement Learning (RL) to optimise call routing in call centres to minimise client waiting time and staff idle time. Two methods are compared: a model-based approach using Value Iteration (VI) under known system dynamics, and a model-free approach using Proximal Policy Optimisation (PPO) that learns from experience. For the model-based approach, a theoretical model is used, while a simulation model combining Discrete Event Simulation (DES) with the OpenAI Gym environment is developed for model-free learning. Both models frame the problem as a Markov Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with Poisson client arrivals and exponentially distributed service and abandonment times. For policy evaluation, random, VI, and PPO policies are evaluated using the simulation model. After 1,000 test episodes, PPO consistently achives the highest rewards, along with the lowest client waiting time and staff idle time, despite requiring longer training time.
#### Summary:
This paper explores the use of Reinforcement Learning (RL) to optimize call routing in call centers, comparing model-based Value Iteration (VI) and model-free Proximal Policy Optimization (PPO). The study frames the problem as a Markov Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with PPO achieving the best performance in minimizing client waiting time and staff idle time despite longer training durations.
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18398

