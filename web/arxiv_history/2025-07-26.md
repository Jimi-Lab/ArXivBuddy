# Daily arXiv Papers
## Date: 2025-07-26
## Description: 用户自定义提示词：

我特别特别特别特别特别特别特别喜欢ai

Zotero文献库分析：
### 主要研究方向
该用户的研究方向主要集中在**软件安全与人工智能的交叉领域**，核心关注点包括：
1. **漏洞检测与防御**：尤其关注深度学习（如Transformer、图神经网络）在静态/动态漏洞检测中的应用（如DeepDFA、DeepWukong、LineVul），以及大语言模型（LLM）在漏洞检测中的潜力（如GPT-4在漏洞检测中的表现）。
2. **大语言模型（LLM）安全**：研究LLM在代码分析、模糊测试、漏洞检测中的能力与局限性（如CodeBERT、LLM驱动的模糊测试），同时关注LLM的安全风险（如提示注入攻击、模型劫持、对抗样本生成）。
3. **AI驱动的攻击与防御**：探索AI模型（如深度学习、LLM）在网络安全中的双向应用，包括攻击（如对抗样本生成、模型后门）和防御（如联邦学习中的隐私保护、鲁棒性增强）。

---

### 感兴趣领域
1. **代码分析与程序理解**：
   - 预训练模型（如CodeBERT）在代码-自然语言双模态任务中的应用。
   - 二进制代码分析（如WebAssembly反编译、二进制代码相似性检测）。
   - 静态程序分析的并行化与中间表示（IR）优化。
2. **AI安全与对抗攻防**：
   - LLM的提示注入攻击（如HOUYI攻击框架）及防御（如设计模式、知识增强的代理框架CRAKEN）。
   - 模型后门攻击（如Imperio语言引导的后门）与防御（如联邦学习中的水印去除Sanitizer）。
   - 多模态系统的对抗攻击（如图像、文本、音频的联合攻击）。
3. **实际系统安全**：
   - 物联网（IoT）生态的LLM威胁检测框架。
   - 微服务架构中的污点分析（如MScan工具）。
   - 区块链欺诈检测的高效语言模型训练（如ZipZap框架）。

---

### 代表性主题
1. **漏洞检测的深度学习方法**：
   - 结合数据流分析与图神经网络（DeepDFA）提升检测效率。
   - 多基单元漏洞（MBU）对检测准确性的影响及改进框架。
   - LLM在漏洞检测中的零样本/小样本能力（如GPT-4超越传统方法）。
2. **LLM安全与代理通信**：
   - LLM代理通信协议（如MCP、A2A）的安全风险与防御。
   - 知识增强的LLM代理（如CRAKEN）在CTF挑战中的应用。
   - 针对LLM集成的红队测试经验（如100个生成式AI产品的对抗测试）。
3. **鲁棒性与隐私保护**：
   - 联邦学习中的高效隐私攻击（EPAFL）与防御（如无害水印）。
   - 个性化隐私保护掩码（P3-Mask）对抗非授权人脸识别。
   - 图神经网络（GNN）后门攻击与图缩减技术的鲁棒性分析。

---

### 常用方法
1. **深度学习与图模型**：
   - Transformer架构（如CodeBERT、基于注意力的模型）和GNN（如DeepWukong）用于代码表示与漏洞检测。
   - 对比学习（如BinCola）提升二进制代码相似性检测的跨域泛化能力。
2. **对抗攻防技术**：
   - 黑盒攻击（如HOUYI）与自适应防御（如STDLens对抗模型劫持）。
   - 集成学习（如FUSE）通过多样性增强检测鲁棒性。
3. **数据驱动优化**：
   - 基于LLM的漏洞样本生成（GVI）解决类别不平衡问题。
   - 轻量级模型压缩（如ZipZap的频率感知压缩）提升训练效率。
4. **静态与动态分析结合**：
   - 混合静态分析（如MScan的污点分析）与动态模糊测试（如LLM驱动的模糊测试）。

---

### 总结
该用户的研究具有鲜明的**跨学科特色**，聚焦于AI技术与软件安全的深度融合，核心目标是提升漏洞检测的自动化能力、增强AI模型的安全性，并探索实际系统中的攻防博弈。其工作兼顾理论创新（如新型鲁棒性指标、知识增强框架）与工程实践（如工具开发、红队测试），同时关注前沿挑战（如LLM代理通信安全、多模态攻击面）。未来可能进一步探索**AI驱动的自动化安全运维**和**可解释的AI安全分析**。

## Papers:
### 1. Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory
#### Abstract:
While large language models (LLMs) leverage both knowledge and reasoning during inference, the capacity to distinguish between them plays a pivotal role in model analysis, interpretability, and development. Inspired by dual-system cognitive theory, we propose a cognition attribution framework to decouple the contribution of knowledge and reasoning. In particular, the cognition of LLMs is decomposed into two distinct yet complementary phases: knowledge retrieval (Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs are prompted to generate answers under two different cognitive modes, fast thinking and slow thinking, respectively. The performance under different cognitive modes is analyzed to quantify the contribution of knowledge and reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results reveal: (1) reasoning adjustment is domain-specific, benefiting reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and potentially imparing knowledge-intensive domains. (2) Parameter scaling improves both knowledge and reasoning, with knowledge improvements being more pronounced. Additionally, parameter scaling make LLMs reasoning significantly more prudent, while moderately more intelligent. (3) Knowledge primarily resides in lower network layers, while reasoning operates in higher layers. Our framework not only helps understand LLMs from a "decoupling" perspective, but also provides new insights into existing research, including scaling laws, hierarchical knowledge editing, and limitations of small-model reasoning.
#### Summary:
该论文受双系统认知理论启发，提出了一种认知归因框架，用于解耦大型语言模型（LLM）中的知识和推理能力。通过将LLM的认知过程分解为知识检索（快速思考）和推理调整（慢速思考）两个阶段，并分析不同认知模式下的表现，量化了知识和推理的贡献。研究覆盖了15个LLM和3个数据集，发现推理调整具有领域特异性，参数扩展对知识和推理均有提升但知识提升更显著，且知识和推理分别主要存在于网络的低层和高层。该框架为理解LLM提供了新视角，并对现有研究如扩展定律、分层知识编辑和小模型推理限制提供了新见解。
#### Relevance Score: 8.0
#### PDF URL: https://arxiv.org/pdf/2507.18178

### 2. Revisiting LLM Reasoning via Information Bottleneck
#### Abstract:
Large language models (LLMs) have recently demonstrated remarkable progress in reasoning capabilities through reinforcement learning with verifiable rewards (RLVR). By leveraging simple rule-based rewards, RL effectively incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning trajectories, progressively guiding them toward correct answers. However, existing approaches remain largely heuristic and intuition-driven, limiting the development of principled methodologies. In this paper, we present a theoretical characterization of LLM reasoning grounded in information bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO), a framework that encourages reasoning trajectories to be both informative about the final correct answer and generalizable across diverse prompts. We derive a practical token-level surrogate objective and propose an efficient approximation, resulting in the lightweight IB regularization method. This technique integrates seamlessly into existing RL-based post-training frameworks without additional computational overhead, requiring only a one-line code modification. Empirically, we validate IB regularization across multiple mathematical reasoning benchmarks and RL algorithms, demonstrating consistent improvements in LLM reasoning performance.
#### Summary:
本文提出了一种基于信息瓶颈（IB）原则的理论框架IB-aware reasoning optimization (IBRO)，用于优化大语言模型（LLM）的推理能力。通过引入IB正则化方法，该框架鼓励推理轨迹既包含关于最终正确答案的信息，又能跨不同提示泛化。该方法可无缝集成到现有的基于强化学习的后训练框架中，无需额外计算开销，并在多个数学推理基准测试中验证了其有效性。
#### Relevance Score: 7.0
#### PDF URL: https://arxiv.org/pdf/2507.18391

### 3. I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis
#### Abstract:
Recent advances in agentic systems for data analysis have emphasized automation of insight generation through multi-agent frameworks, and orchestration layers. While these systems effectively manage tasks like query translation, data transformation, and visualization, they often overlook the structured reasoning process underlying analytical thinking. Reasoning large language models (LLMs) used for multi-step problem solving are trained as general-purpose problem solvers. As a result, their reasoning or thinking steps do not adhere to fixed processes for specific tasks. Real-world data analysis requires a consistent cognitive workflow: interpreting vague goals, grounding them in contextual knowledge, constructing abstract plans, and adapting execution based on intermediate outcomes. We introduce I2I-STRADA (Information-to-Insight via Structured Reasoning Agent for Data Analysis), an agentic architecture designed to formalize this reasoning process. I2I-STRADA focuses on modeling how analysis unfolds via modular sub-tasks that reflect the cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench benchmarks show that I2I-STRADA outperforms prior systems in planning coherence and insight alignment, highlighting the importance of structured cognitive workflows in agent design for data analysis.
#### Summary:
这篇论文介绍了I2I-STRADA，一种用于数据分析的结构化推理代理架构。该架构通过模块化子任务模拟分析推理的认知步骤，旨在规范化数据分析中的推理过程。与现有多代理框架不同，I2I-STRADA强调结构化认知工作流，包括解释模糊目标、基于上下文知识进行基础构建、制定抽象计划以及根据中间结果调整执行。在DABstep和DABench基准测试中，I2I-STRADA在规划一致性和洞察对齐方面优于先前系统，证明了结构化认知工作流在数据分析代理设计中的重要性。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.17874

### 4. AlphaGo Moment for Model Architecture Discovery
#### Abstract:
While AI systems demonstrate exponentially improving capabilities, the pace of AI research itself remains linearly bounded by human cognitive capacity, creating an increasingly severe development bottleneck. We present ASI-Arch, the first demonstration of Artificial Superintelligence for AI research (ASI4AI) in the critical domain of neural architecture discovery--a fully autonomous system that shatters this fundamental constraint by enabling AI to conduct its own architectural innovation. Moving beyond traditional Neural Architecture Search (NAS), which is fundamentally limited to exploring human-defined spaces, we introduce a paradigm shift from automated optimization to automated innovation. ASI-Arch can conduct end-to-end scientific research in the domain of architecture discovery, autonomously hypothesizing novel architectural concepts, implementing them as executable code, training and empirically validating their performance through rigorous experimentation and past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000 GPU hours, culminating in the discovery of 106 innovative, state-of-the-art (SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed unexpected strategic insights invisible to human players, our AI-discovered architectures demonstrate emergent design principles that systematically surpass human-designed baselines and illuminate previously unknown pathways for architectural innovation. Crucially, we establish the first empirical scaling law for scientific discovery itself--demonstrating that architectural breakthroughs can be scaled computationally, transforming research progress from a human-limited to a computation-scalable process. We provide comprehensive analysis of the emergent design patterns and autonomous research capabilities that enabled these breakthroughs, establishing a blueprint for self-accelerating AI systems.
#### Summary:
这篇论文介绍了ASI-Arch系统，这是首个在神经架构发现领域展示人工超级智能（ASI4AI）的全自主系统。ASI-Arch能够自主提出新颖的架构概念、实现可执行代码、并通过实验验证其性能，突破了传统神经架构搜索（NAS）的限制。该系统进行了1,773次自主实验，发现了106种创新的线性注意力架构，其设计原则超越了人类设计的基线，并建立了科学发现本身的扩展定律。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18074

### 5. Logical Characterizations of GNNs with Mean Aggregation
#### Abstract:
We study the expressive power of graph neural networks (GNNs) with mean as the aggregation function. In the non-uniform setting, we show that such GNNs have exactly the same expressive power as ratio modal logic, which has modal operators expressing that at least a certain ratio of the successors of a vertex satisfies a specified property. The non-uniform expressive power of mean GNNs is thus higher than that of GNNs with max aggregation, but lower than for sum aggregation--the latter are characterized by modal logic and graded modal logic, respectively. In the uniform setting, we show that the expressive power relative to MSO is exactly that of alternation-free modal logic, under the natural assumptions that combination functions are continuous and classification functions are thresholds. This implies that, relative to MSO and in the uniform setting, mean GNNs are strictly less expressive than sum GNNs and max GNNs. When any of the assumptions is dropped, the expressive power increases.
#### Summary:
该论文研究了使用均值聚合的图神经网络（GNNs）的表达能力。在非均匀设置下，这类GNNs的表达能力等同于比率模态逻辑，其模态运算符表示顶点后继中至少满足特定属性的比例。因此，均值GNNs的表达能力高于使用最大聚合的GNNs，但低于使用求和聚合的GNNs。在均匀设置下，假设组合函数连续且分类函数为阈值时，均值GNNs相对于MSO的表达能力等同于无交替模态逻辑。这意味着在均匀设置下，均值GNNs的表达能力严格低于求和和最大聚合的GNNs。若假设不成立，表达能力会增强。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18145

### 6. SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law
#### Abstract:
We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha' moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI.
#### Summary:
论文介绍了SafeWork-R1，一种多模态推理模型，通过SafeLadder框架实现能力与安全的协同进化。该框架采用大规模、渐进式、安全导向的强化学习后训练，并结合多原则验证器，使模型具备内在安全推理和自我反思能力。SafeWork-R1在安全相关基准测试中表现优异，优于GPT-4.1和Claude Opus 4等专有模型，同时不损害一般能力。论文还提出了两种推理时干预方法和审议搜索机制，以增强可靠性，并展示了该框架在不同模型上的通用性。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18576

### 7. SMARTAPS: Tool-augmented LLMs for Operations Management
#### Abstract:
Large language models (LLMs) present intriguing opportunities to enhance user interaction with traditional algorithms and tools in real-world applications. An advanced planning system (APS) is a sophisticated software that leverages optimization to help operations planners create, interpret, and modify an operational plan. While highly beneficial, many customers are priced out of using an APS due to the ongoing costs of consultants responsible for customization and maintenance. To address the need for a more accessible APS expressed by supply chain planners, we present SmartAPS, a conversational system built on a tool-augmented LLM. Our system provides operations planners with an intuitive natural language chat interface, allowing them to query information, perform counterfactual reasoning, receive recommendations, and execute scenario analysis to better manage their operation. A short video demonstrating the system has been released: this https URL
#### Summary:
这篇论文介绍了SmartAPS，一个基于工具增强的大型语言模型（LLM）的对话系统，旨在为运营规划者提供更易访问的高级规划系统（APS）。通过自然语言聊天界面，用户可以进行信息查询、反事实推理、接收建议和执行场景分析，从而更好地管理运营。该系统解决了传统APS因定制和维护成本高而难以普及的问题。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.17927

### 8. Multi-Agent Guided Policy Optimization
#### Abstract:
Due to practical constraints such as partial observability and limited communication, Centralized Training with Decentralized Execution (CTDE) has become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning (MARL). However, existing CTDE methods often underutilize centralized training or lack theoretical guarantees. We propose Multi-Agent Guided Policy Optimization (MAGPO), a novel framework that better leverages centralized training by integrating centralized guidance with decentralized execution. MAGPO uses an auto-regressive joint policy for scalable, coordinated exploration and explicitly aligns it with decentralized policies to ensure deployability under partial observability. We provide theoretical guarantees of monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across 6 diverse environments. Results show that MAGPO consistently outperforms strong CTDE baselines and matches or surpasses fully centralized approaches, offering a principled and practical solution for decentralized multi-agent learning. Our code and experimental data can be found in this https URL.
#### Summary:
该论文提出了一种名为多智能体引导策略优化（MAGPO）的新框架，旨在更好地利用集中式训练与分散式执行（CTDE）范式。MAGPO通过整合集中式引导与分散式执行，使用自回归联合策略进行可扩展的协调探索，并明确将其与分散式策略对齐，以确保在部分可观测性下的可部署性。论文提供了单调策略改进的理论保证，并在6个不同环境的43个任务上进行了实证评估，结果表明MAGPO始终优于强CTDE基线，并匹配或超越完全集中式方法。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18059

### 9. Agentic AI framework for End-to-End Medical Data Inference
#### Abstract:
Building and deploying machine learning solutions in healthcare remains expensive and labor-intensive due to fragmented preprocessing workflows, model compatibility issues, and stringent data privacy constraints. In this work, we introduce an Agentic AI framework that automates the entire clinical data pipeline, from ingestion to inference, through a system of modular, task-specific agents. These agents handle both structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing recommendation without manual intervention. We evaluate the system on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging. For example, in the case of structured data (anxiety data) and unstructured data (colonoscopy polyps data), the pipeline begins with file-type detection by the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring privacy compliance, where we first identify the data type and then anonymize it. The Feature Extraction Agent identifies features using an embedding-based approach for tabular data, extracting all column names, and a multi-stage MedGemma-based approach for image data, which infers modality and disease name. These features guide the Model-Data Feature Matcher Agent in selecting the best-fit model from a curated repository. The Preprocessing Recommender Agent and Preprocessing Implementor Agent then apply tailored preprocessing based on data type and model requirements. Finally, the ``Model Inference Agent" runs the selected model on the uploaded data and generates interpretable outputs using tools like SHAP, LIME, and DETR attention maps. By automating these high-friction stages of the ML lifecycle, the proposed framework reduces the need for repeated expert intervention, offering a scalable, cost-efficient pathway for operationalizing AI in clinical environments.
#### Summary:
这篇论文提出了一种名为Agentic AI的框架，旨在自动化医疗数据的端到端处理流程，从数据摄入到推理输出。该框架通过模块化、任务特定的代理系统，处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐，无需人工干预。系统在老年医学、姑息治疗和结肠镜成像等公开数据集上进行了评估，展示了其在临床环境中降低专家干预需求、提高AI操作效率的潜力。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18115

### 10. Foundations for Risk Assessment of AI in Protecting Fundamental Rights
#### Abstract:
This chapter introduces a conceptual framework for qualitative risk assessment of AI, particularly in the context of the EU AI Act. The framework addresses the complexities of legal compliance and fundamental rights protection by itegrating definitional balancing and defeasible reasoning. Definitional balancing employs proportionality analysis to resolve conflicts between competing rights, while defeasible reasoning accommodates the dynamic nature of legal decision-making. Our approach stresses the need for an analysis of AI deployment scenarios and for identifying potential legal violations and multi-layered impacts on fundamental rights. On the basis of this analysis, we provide philosophical foundations for a logical account of AI risk analysis. In particular, we consider the basic building blocks for conceptually grasping the interaction between AI deployment scenarios and fundamental rights, incorporating in defeasible reasoning definitional balancing and arguments about the contextual promotion or demotion of rights. This layered approach allows for more operative models of assessment of both high-risk AI systems and General Purpose AI (GPAI) systems, emphasizing the broader applicability of the latter. Future work aims to develop a formal model and effective algorithms to enhance AI risk assessment, bridging theoretical insights with practical applications to support responsible AI governance.
#### Summary:
本章介绍了一个用于定性评估AI风险的概念框架，特别是在欧盟AI法案的背景下。该框架通过整合定义性平衡和可废止推理，解决了法律合规性和基本权利保护的复杂性。定义性平衡采用比例分析来解决竞争权利之间的冲突，而可废止推理则适应法律决策的动态性。该方法强调分析AI部署场景、识别潜在法律违规行为以及对基本权利的多层次影响。在此基础上，提供了AI风险分析的哲学基础，特别是概念化AI部署场景与基本权利之间互动的基本构建块。未来工作旨在开发形式化模型和有效算法，以增强AI风险评估，将理论见解与实际应用相结合，支持负责任的AI治理。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18290

### 11. Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios
#### Abstract:
Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step logic. In finance, however, professionals must not only converge on optimal decisions but also generate creative, plausible futures under uncertainty. We introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent thinking in LLMs for financial tasks.
ConDiFi features 607 macro-financial prompts for divergent reasoning and 990 multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we evaluated 14 leading models and uncovered striking differences. Despite high fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models like DeepSeek-R1 and Cohere Command R+ rank among the top for generating actionable, insights suitable for investment decisions. ConDiFi provides a new perspective to assess reasoning capabilities essential to safe and strategic deployment of LLMs in finance.
#### Summary:
这篇论文介绍了ConDiFi基准测试，用于评估大型语言模型（LLM）在金融场景中的发散性和收敛性思维能力。ConDiFi包含607个宏观金融提示用于发散性推理和990个多跳对抗性多选题用于收敛性推理。研究评估了14个领先模型，发现GPT-4o在新颖性和可操作性方面表现不佳，而DeepSeek-R1和Cohere Command R+在生成适用于投资决策的可操作见解方面表现优异。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18368

### 12. ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics
#### Abstract:
Unlike conventional Machine-Learning (ML) approaches, often criticized as "black boxes", Symbolic Regression (SR) stands out as a powerful tool for revealing interpretable mathematical relationships in complex physical systems, requiring no a priori assumptions about models' structures. Motivated by the recognition that, in fluid mechanics, an understanding of the underlying flow physics is as crucial as accurate prediction, this study applies SR to model a fundamental three-dimensional (3D) incompressible flow in a rectangular channel, focusing on the (axial) velocity and pressure fields under laminar conditions. By employing the PySR library, compact symbolic equations were derived directly from numerical simulation data, revealing key characteristics of the flow dynamics. These equations not only approximate the parabolic velocity profile and pressure drop observed in the studied fluid flow, but also perfectly coincide with analytical solutions from the literature. Furthermore, we propose an innovative approach that integrates SR with the knowledge-representation framework of Answer Set Programming (ASP), combining the generative power of SR with the declarative reasoning strengths of ASP. The proposed hybrid SR/ASP framework ensures that the SR-generated symbolic expressions are not only statistically accurate, but also physically plausible, adhering to domain-specific principles. Overall, the study highlights two key contributions: SR's ability to simplify complex flow behaviours into concise, interpretable equations, and the potential of knowledge-representation approaches to improve the reliability and alignment of data-driven SR models with domain principles. Insights from the examined 3D channel flow pave the way for integrating such hybrid approaches into efficient frameworks, [...] where explainable predictions and real-time data analysis are crucial.
#### Summary:
该论文提出了一种结合符号回归（SR）与答案集编程（ASP）的混合方法，用于流体力学中的物理建模。通过PySR库从数值模拟数据中推导出紧凑的符号方程，揭示了三维矩形通道中层流条件下轴向速度和压力场的关键动态特性。这些方程不仅与文献中的解析解完美吻合，还通过ASP框架确保生成的表达式在统计准确的同时符合物理原理。研究突出了SR将复杂流动行为简化为可解释方程的能力，以及知识表示方法提升数据驱动模型可靠性的潜力。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.17777

### 13. E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI
#### Abstract:
How can AI move beyond imitation toward genuine creativity? This paper proposes the E.A.R.T.H. framework, a five-stage generative pipeline that transforms model-generated errors into creative assets through Error generation, Amplification, Refine selection, Transform, and Harness feedback. Drawing on cognitive science and generative modeling, we posit that "creative potential hides in failure" and operationalize this via structured prompts, semantic scoring, and human-in-the-loop evaluation. Implemented using LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the pipeline employs a composite reward function based on novelty, surprise, and relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to 1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4% improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a 4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment (CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones (3.99). Feedback highlights stylistic precision and emotional resonance. These results demonstrate that error-centered, feedback-driven generation enhances creativity, offering a scalable path toward self-evolving, human-aligned creative AI.
#### Summary:
这篇论文提出了E.A.R.T.H.框架，一个五阶段的生成式AI流程，通过错误生成、放大、精炼选择、转换和利用反馈，将模型生成的错误转化为创意资产。该框架结合认知科学和生成模型，通过结构化提示、语义评分和人工参与评估，显著提升了创意输出。实验结果显示，创意分数提高了52.5%，最终输出提升了70.4%，且在多模态测试和人工评估中表现优异。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18004

### 14. Does visualization help AI understand data?
#### Abstract:
Charts and graphs help people analyze data, but can they also be useful to AI systems? To investigate this question, we perform a series of experiments with two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three representative analysis tasks, the two systems describe synthetic datasets more precisely and accurately when raw data is accompanied by a scatterplot, especially as datasets grow in complexity. Comparison with two baselines -- providing a blank chart and a chart with mismatched data -- shows that the improved performance is due to the content of the charts. Our results are initial evidence that AI systems, like humans, can benefit from visualization.
#### Summary:
这篇论文探讨了可视化是否有助于AI系统理解数据。通过实验，研究发现商业视觉语言模型（如GPT 4.1和Claude 3.5）在分析合成数据集时，当原始数据伴随散点图时，描述更精确和准确，尤其是在数据集复杂度增加时。与空白图表或数据不匹配的图表相比，性能提升归因于图表内容。结果表明，AI系统可能像人类一样从可视化中受益。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18022

### 15. The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams
#### Abstract:
We present our method for automatically marking Physics exams. The marking problem consists in assessing typed student answers for correctness with respect to a ground truth solution. This is a challenging problem that we seek to tackle using a combination of a computer algebra system, an SMT solver and a term rewriting system. A Large Language Model is used to interpret and remove errors from student responses and rewrite these in a machine readable format. Once formalized and language-aligned, the next step then consists in applying automated reasoning techniques for assessing student solution correctness. We consider two methods of automated theorem proving: off-the-shelf SMT solving and term rewriting systems tailored for physics problems involving trigonometric expressions. The development of the term rewrite system and establishing termination and confluence properties was not trivial, and we describe it in some detail in the paper. We evaluate our system on a rich pool of over 1500 real-world student exam responses from the 2023 Australian Physics Olympiad.
#### Summary:
该论文提出了一种自动批改物理考试的方法，结合了计算机代数系统、SMT求解器和项重写系统，利用大语言模型（LLM）处理学生答案并转换为机器可读格式，随后通过自动推理技术评估答案正确性。论文详细描述了针对三角表达式的项重写系统的开发及其终止性和合流性证明，并在1500多份真实学生考试答案上进行了评估。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18337

### 16. On the Performance of Concept Probing: The Influence of the Data (Extended Version)
#### Abstract:
Concept probing has recently garnered increasing interest as a way to help interpret artificial neural networks, dealing both with their typically large size and their subsymbolic nature, which ultimately renders them unfeasible for direct human interpretation. Concept probing works by training additional classifiers to map the internal representations of a model into human-defined concepts of interest, thus allowing humans to peek inside artificial neural networks. Research on concept probing has mainly focused on the model being probed or the probing model itself, paying limited attention to the data required to train such probing models. In this paper, we address this gap. Focusing on concept probing in the context of image classification tasks, we investigate the effect of the data used to train probing models on their performance. We also make available concept labels for two widely used datasets.
#### Summary:
这篇论文研究了概念探测（concept probing）在人工神经网络解释中的性能，特别关注了用于训练探测模型的数据对其性能的影响。作者通过在图像分类任务中进行实验，探讨了不同数据对探测模型表现的作用，并公开了两个广泛使用的数据集的标签。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18550

### 17. Synthesis of timeline-based planning strategies avoiding determinization
#### Abstract:
Qualitative timeline-based planning models domains as sets of independent, but
interacting, components whose behaviors over time, the timelines, are governed
by sets of qualitative temporal constraints (ordering relations), called
synchronization rules.
Its plan-existence problem has been shown to be PSPACE-complete; in
particular, PSPACE-membership has been proved via reduction to the
nonemptiness problem for nondeterministic finite automata.
However, nondeterministic automata cannot be directly used to synthesize
planning strategies as a costly determinization step is needed.
In this paper, we identify a fragment of qualitative timeline-based planning
whose plan-existence problem can be directly mapped into the nonemptiness
problem of deterministic finite automata, which can then
synthesize strategies.
In addition, we identify a maximal subset of Allen's relations that fits into
such a deterministic fragment.
#### Summary:
该论文研究了一种基于时间线的定性规划方法，通过将规划问题映射到确定性有限自动机（DFA）的非空性问题，避免了传统方法中所需的非确定性有限自动机（NFA）的确定性化步骤。作者识别了一个特定的规划片段，可以直接使用DFA合成规划策略，并确定了适合该确定性片段的Allen关系的最大子集。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.17988

### 18. Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes
#### Abstract:
The rapid development of COVID-19 vaccines has showcased the global communitys ability to combat infectious diseases. However, the need for post-licensure surveillance systems has grown due to the limited window for safety data collection in clinical trials and early widespread implementation. This study aims to employ Natural Language Processing techniques and Active Learning to rapidly develop a classifier that detects potential vaccine safety issues from emergency department notes. ED triage notes, containing expert, succinct vital patient information at the point of entry to health systems, can significantly contribute to timely vaccine safety signal surveillance. While keyword-based classification can be effective, it may yield false positives and demand extensive keyword modifications. This is exacerbated by the infrequency of vaccination-related ED presentations and their similarity to other reasons for ED visits. NLP offers a more accurate and efficient alternative, albeit requiring annotated data, which is often scarce in the medical field. Active learning optimizes the annotation process and the quality of annotated data, which can result in faster model implementation and improved model performance. This work combines active learning, data augmentation, and active learning and evaluation techniques to create a classifier that is used to enhance vaccine safety surveillance from ED triage notes.
#### Summary:
该论文探讨了利用自然语言处理（NLP）技术和主动学习（Active Learning）从急诊科分诊笔记中快速开发分类器，以检测潜在的疫苗安全问题。由于临床试验中安全数据收集的时间有限，以及疫苗广泛使用后可能出现的安全问题，这种基于ED分诊笔记的监测系统显得尤为重要。论文提出结合主动学习、数据增强和评估技术，优化标注过程和数据质量，从而提高分类器的性能和实施速度，以支持疫苗安全信号的监测。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18123

### 19. Comparing Non-minimal Semantics for Disjunction in Answer Set Programming
#### Abstract:
In this paper, we compare four different semantics for disjunction in Answer Set Programming that, unlike stable models, do not adhere to the principle of model minimality. Two of these approaches, Cabalar and Muñiz' \emph{Justified Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly provide an alternative non-minimal semantics for disjunction. The other two, Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference} (DI) semantics, actually introduce a new disjunction connective, but are compared here as if they constituted new semantics for the standard disjunction operator. We are able to prove that three of these approaches (Forks, Justified Models and a reasonable relaxation of the DI semantics) actually coincide, constituting a common single approach under different definitions. Moreover, this common semantics always provides a superset of the stable models of a program (in fact, modulo any context) and is strictly stronger than the fourth approach (Strongly Supported Models), that actually treats disjunctions as in classical logic.
#### Summary:
该论文比较了答案集编程（Answer Set Programming）中四种非最小语义的析取处理方法，包括Justified Models、Strongly Supported Models、Forks和Determining Inference语义。研究发现其中三种方法（Forks、Justified Models和DI语义的合理松弛）实际上是一致的，构成了不同定义下的共同方法，且这些方法始终提供程序稳定模型的超集。而Strongly Supported Models方法则将析取视为经典逻辑中的处理方式。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18198

### 20. Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation
#### Abstract:
This paper investigates the application of Reinforcement Learning (RL) to optimise call routing in call centres to minimise client waiting time and staff idle time. Two methods are compared: a model-based approach using Value Iteration (VI) under known system dynamics, and a model-free approach using Proximal Policy Optimisation (PPO) that learns from experience. For the model-based approach, a theoretical model is used, while a simulation model combining Discrete Event Simulation (DES) with the OpenAI Gym environment is developed for model-free learning. Both models frame the problem as a Markov Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with Poisson client arrivals and exponentially distributed service and abandonment times. For policy evaluation, random, VI, and PPO policies are evaluated using the simulation model. After 1,000 test episodes, PPO consistently achives the highest rewards, along with the lowest client waiting time and staff idle time, despite requiring longer training time.
#### Summary:
本文研究了强化学习（RL）在呼叫中心优化呼叫路由中的应用，比较了基于模型的价值迭代（VI）方法和无模型的近端策略优化（PPO）方法，旨在最小化客户等待时间和员工空闲时间。研究通过理论模型和仿真模型（结合离散事件仿真和OpenAI Gym环境）进行实验，结果显示PPO在奖励、客户等待时间和员工空闲时间方面表现最佳，尽管训练时间较长。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18398

