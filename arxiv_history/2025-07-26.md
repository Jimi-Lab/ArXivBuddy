# Daily arXiv Papers
## Date: 2025-07-26
## Description: 我是一名在读博士，对agent for Security、二进制安全研究、逆向工程、多模态、LLM领域感兴趣。



## Papers:
### 1. Learning to Locate: GNN-Powered Vulnerability Path Discovery in Open Source Code
#### Abstract:
Detecting security vulnerabilities in open-source software is a critical task that is highly regarded in the related research communities. Several approaches have been proposed in the literature for detecting vulnerable codes and identifying the classes of vulnerabilities. However, there is still room to work in explaining the root causes of detected vulnerabilities through locating vulnerable statements and the discovery of paths leading to the activation of the vulnerability. While frameworks like SliceLocator offer explanations by identifying vulnerable paths, they rely on rule-based sink identification that limits their generalization. In this paper, we introduce VulPathFinder, an explainable vulnerability path discovery framework that enhances SliceLocator's methodology by utilizing a novel Graph Neural Network (GNN) model for detecting sink statements, rather than relying on predefined rules. The proposed GNN captures semantic and syntactic dependencies to find potential sink points (PSPs), which are candidate statements where vulnerable paths end. After detecting PSPs, program slicing can be used to extract potentially vulnerable paths, which are then ranked by feeding them back into the target graph-based detector. Ultimately, the most probable path is returned, explaining the root cause of the detected vulnerability. We demonstrated the effectiveness of the proposed approach by performing evaluations on a benchmark of the buffer overflow CWEs from the SARD dataset, providing explanations for the corresponding detected vulnerabilities. The results show that VulPathFinder outperforms both original SliceLocator and GNNExplainer (as a general GNN explainability tool) in discovery of vulnerability paths to identified PSPs.
#### Summary:
这篇论文提出了VulPathFinder，一个可解释的漏洞路径发现框架，通过使用图神经网络（GNN）模型来检测漏洞的潜在汇聚点（PSPs），从而改进现有的基于规则的漏洞定位方法。VulPathFinder能够捕捉代码的语义和句法依赖关系，识别潜在的漏洞路径，并通过程序切片和排名机制返回最可能的漏洞路径，解释漏洞的根本原因。论文在SARD数据集的缓冲区溢出CWE基准测试中验证了其有效性，结果显示VulPathFinder在漏洞路径发现方面优于现有的SliceLocator和GNNExplainer。
#### Relevance Score: 8.0
#### PDF URL: https://arxiv.org/pdf/2507.17888

### 2. RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models
#### Abstract:
Resource Consumption Attacks (RCAs) have emerged as a significant threat to the deployment of Large Language Models (LLMs). With the integration of vision modalities, additional attack vectors exacerbate the risk of RCAs in large vision-language models (LVLMs). However, existing red-teaming studies have largely overlooked visual inputs as a potential attack surface, resulting in insufficient mitigation strategies against RCAs in LVLMs. To address this gap, we propose RECALLED (\textbf{RE}source \textbf{C}onsumption \textbf{A}ttack on \textbf{L}arge Vision-\textbf{L}anguag\textbf{E} Mo\textbf{D}els), the first approach for exploiting visual modalities to trigger unbounded RCAs red-teaming. First, we present \textit{Vision Guided Optimization}, a fine-grained pixel-level optimization, to obtain \textit{Output Recall} adversarial perturbations, which can induce repeating output. Then, we inject the perturbations into visual inputs, triggering unbounded generations to achieve the goal of RCAs. Additionally, we introduce \textit{Multi-Objective Parallel Losses} to generate universal attack templates and resolve optimization conflicts when intending to implement parallel attacks. Empirical results demonstrate that RECALLED increases service response latency by over 26 $\uparrow$, resulting in an additional 20\% increase in GPU utilization and memory consumption. Our study exposes security vulnerabilities in LVLMs and establishes a red-teaming framework that can facilitate future defense development against RCAs.
#### Summary:
这篇论文提出了RECALLED方法，针对大型视觉语言模型（LVLMs）的资源消耗攻击（RCAs）。通过视觉引导优化和像素级优化，生成能够诱导重复输出的对抗性扰动，从而触发无限生成，导致服务延迟和资源消耗增加。研究还引入了多目标并行损失来生成通用攻击模板，并解决了并行攻击中的优化冲突。实验结果表明，RECALLED显著增加了服务响应延迟和GPU利用率，揭示了LVLMs的安全漏洞。
#### Relevance Score: 8.0
#### PDF URL: https://arxiv.org/pdf/2507.18053

### 3. Information Security Based on LLM Approaches: A Review
#### Abstract:
Information security is facing increasingly severe challenges, and traditional protection means are difficult to cope with complex and changing threats. In recent years, as an emerging intelligent technology, large language models (LLMs) have shown a broad application prospect in the field of information security. In this paper, we focus on the key role of LLM in information security, systematically review its application progress in malicious behavior prediction, network threat analysis, system vulnerability detection, malicious code identification, and cryptographic algorithm optimization, and explore its potential in enhancing security protection performance. Based on neural networks and Transformer architecture, this paper analyzes the technical basis of large language models and their advantages in natural language processing tasks. It is shown that the introduction of large language modeling helps to improve the detection accuracy and reduce the false alarm rate of security systems. Finally, this paper summarizes the current application results and points out that it still faces challenges in model transparency, interpretability, and scene adaptability, among other issues. It is necessary to explore further the optimization of the model structure and the improvement of the generalization ability to realize a more intelligent and accurate information security protection system.
#### Summary:
本文综述了大型语言模型（LLMs）在信息安全领域的应用进展，包括恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和密码算法优化等方面。论文分析了LLMs基于神经网络和Transformer架构的技术基础及其在自然语言处理任务中的优势，指出LLMs有助于提高安全系统的检测准确率和降低误报率。同时，论文也总结了当前应用成果，并指出LLMs在模型透明度、可解释性和场景适应性等方面仍面临挑战，需要进一步探索模型结构的优化和泛化能力的提升，以实现更智能和准确的信息安全保护系统。
#### Relevance Score: 8.0
#### PDF URL: https://arxiv.org/pdf/2507.18215

### 4. Revisiting LLM Reasoning via Information Bottleneck
#### Abstract:
Large language models (LLMs) have recently demonstrated remarkable progress in reasoning capabilities through reinforcement learning with verifiable rewards (RLVR). By leveraging simple rule-based rewards, RL effectively incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning trajectories, progressively guiding them toward correct answers. However, existing approaches remain largely heuristic and intuition-driven, limiting the development of principled methodologies. In this paper, we present a theoretical characterization of LLM reasoning grounded in information bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO), a framework that encourages reasoning trajectories to be both informative about the final correct answer and generalizable across diverse prompts. We derive a practical token-level surrogate objective and propose an efficient approximation, resulting in the lightweight IB regularization method. This technique integrates seamlessly into existing RL-based post-training frameworks without additional computational overhead, requiring only a one-line code modification. Empirically, we validate IB regularization across multiple mathematical reasoning benchmarks and RL algorithms, demonstrating consistent improvements in LLM reasoning performance.
#### Summary:
这篇论文提出了一个基于信息瓶颈（IB）原则的理论框架IBRO，用于优化大型语言模型（LLM）的推理能力。通过引入IB正则化方法，论文旨在使推理轨迹既包含关于最终正确答案的信息，又能泛化到不同的提示上。该方法可以无缝集成到现有的基于强化学习的后训练框架中，无需额外计算开销。实验结果表明，该方法在多个数学推理基准和强化学习算法中均能提高LLM的推理性能。
#### Relevance Score: 7.0
#### PDF URL: https://arxiv.org/pdf/2507.18391

### 5. Scout: Leveraging Large Language Models for Rapid Digital Evidence Discovery
#### Abstract:
Recent technological advancements and the prevalence of technology in day to day activities have caused a major increase in the likelihood of the involvement of digital evidence in more and more legal investigations. Consumer-grade hardware is growing more powerful, with expanding memory and storage sizes and enhanced processor capabilities. Forensics investigators often have to sift through gigabytes of data during an ongoing investigation making the process tedious. Memory forensics, disk analysis all are well supported by state of the art tools that significantly lower the effort required to be put in by a forensic investigator by providing string searches, analyzing images file etc. During the course of the investigation a lot of false positives are identified that need to be lowered. This work presents Scout, a digital forensics framework that performs preliminary evidence processing and prioritizing using large language models. Scout deploys foundational language models to identify relevant artifacts from a large number of potential evidence files (disk images, captured network packets, memory dumps etc.) which would have taken longer to get identified. Scout employs text based large language models can easily process files with textual information. For the forensic analysis of multimedia files like audio, image, video, office documents etc. multimodal models are employed by Scout. Scout was able to identify and realize the evidence file that were of potential interest for the investigator.
#### Summary:
这篇论文介绍了Scout，一个利用大型语言模型进行数字证据快速发现的法医框架。Scout通过部署基础语言模型和多模态模型，能够从大量潜在证据文件（如磁盘映像、捕获的网络数据包、内存转储等）中识别出相关证据，从而减轻法医调查人员的工作负担。该框架能够处理文本信息和多媒体文件，有效降低调查过程中的误报率。
#### Relevance Score: 7.0
#### PDF URL: https://arxiv.org/pdf/2507.18478

### 6. I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis
#### Abstract:
Recent advances in agentic systems for data analysis have emphasized automation of insight generation through multi-agent frameworks, and orchestration layers. While these systems effectively manage tasks like query translation, data transformation, and visualization, they often overlook the structured reasoning process underlying analytical thinking. Reasoning large language models (LLMs) used for multi-step problem solving are trained as general-purpose problem solvers. As a result, their reasoning or thinking steps do not adhere to fixed processes for specific tasks. Real-world data analysis requires a consistent cognitive workflow: interpreting vague goals, grounding them in contextual knowledge, constructing abstract plans, and adapting execution based on intermediate outcomes. We introduce I2I-STRADA (Information-to-Insight via Structured Reasoning Agent for Data Analysis), an agentic architecture designed to formalize this reasoning process. I2I-STRADA focuses on modeling how analysis unfolds via modular sub-tasks that reflect the cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench benchmarks show that I2I-STRADA outperforms prior systems in planning coherence and insight alignment, highlighting the importance of structured cognitive workflows in agent design for data analysis.
#### Summary:
这篇论文介绍了I2I-STRADA，一种用于数据分析的结构化推理代理架构。该架构旨在通过模块化子任务来模拟分析推理的认知步骤，从而规范化数据分析中的推理过程。I2I-STRADA在DABstep和DABench基准测试中表现优于之前的系统，强调了结构化认知工作流在代理设计中的重要性。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.17874

### 7. Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory
#### Abstract:
While large language models (LLMs) leverage both knowledge and reasoning during inference, the capacity to distinguish between them plays a pivotal role in model analysis, interpretability, and development. Inspired by dual-system cognitive theory, we propose a cognition attribution framework to decouple the contribution of knowledge and reasoning. In particular, the cognition of LLMs is decomposed into two distinct yet complementary phases: knowledge retrieval (Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs are prompted to generate answers under two different cognitive modes, fast thinking and slow thinking, respectively. The performance under different cognitive modes is analyzed to quantify the contribution of knowledge and reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results reveal: (1) reasoning adjustment is domain-specific, benefiting reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and potentially imparing knowledge-intensive domains. (2) Parameter scaling improves both knowledge and reasoning, with knowledge improvements being more pronounced. Additionally, parameter scaling make LLMs reasoning significantly more prudent, while moderately more intelligent. (3) Knowledge primarily resides in lower network layers, while reasoning operates in higher layers. Our framework not only helps understand LLMs from a "decoupling" perspective, but also provides new insights into existing research, including scaling laws, hierarchical knowledge editing, and limitations of small-model reasoning.
#### Summary:
这篇论文受双系统认知理论启发，提出了一个认知归因框架，用于解耦大型语言模型（LLMs）中的知识和推理能力。通过将LLMs的认知过程分解为知识检索（快速思考）和推理调整（慢速思考）两个阶段，作者分析了15个LLMs在3个数据集上的表现。研究发现：（1）推理调整具有领域特异性，对数学、物理等推理密集型领域有益，但可能损害知识密集型领域；（2）参数缩放同时提升知识和推理能力，但对知识的提升更显著，并使LLMs的推理更加谨慎和智能；（3）知识主要存在于网络低层，而推理则在高层进行。该框架不仅从解耦角度帮助理解LLMs，还为现有研究（如缩放定律、分层知识编辑和小模型推理的局限性）提供了新见解。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18178

### 8. SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law
#### Abstract:
We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha' moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI.
#### Summary:
论文介绍了SafeWork-R1，一种多模态推理模型，通过SafeLadder框架实现了能力和安全的协同进化。该框架采用大规模、渐进式、以安全为导向的强化学习后训练，并配备多原则验证器。SafeWork-R1不仅提升了基础模型Qwen2.5-VL-72B在安全相关基准上的表现（平均提升46.54%），还在不牺牲通用能力的情况下，达到了与GPT-4.1和Claude Opus 4等领先专有模型相当的安全性能。此外，论文还提出了两种推理时干预方法和一种审议搜索机制，以增强模型的可靠性。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18576

### 9. MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection
#### Abstract:
Phishing emails continue to pose a significant threat to cybersecurity by exploiting human vulnerabilities through deceptive content and malicious payloads. While Machine Learning (ML) models are effective at detecting phishing threats, their performance largely relies on the quality and diversity of the training data. This paper presents MeAJOR (Merged email Assets from Joint Open-source Repositories) Corpus, a novel, multi-source phishing email dataset designed to overcome critical limitations in existing resources. It integrates 135894 samples representing a broad number of phishing tactics and legitimate emails, with a wide spectrum of engineered features. We evaluated the dataset's utility for phishing detection research through systematic experiments with four classification models (RF, XGB, MLP, and CNN) across multiple feature configurations. Results highlight the dataset's effectiveness, achieving 98.34% F1 with XGB. By integrating broad features from multiple categories, our dataset provides a reusable and consistent resource, while addressing common challenges like class imbalance, generalisability and reproducibility.
#### Summary:
这篇论文介绍了MeAJOR Corpus，一个多源的钓鱼邮件检测数据集，旨在解决现有资源的关键限制。该数据集整合了135,894个样本，涵盖了广泛的钓鱼策略和合法邮件，并包含多种工程特征。通过四种分类模型（RF、XGB、MLP和CNN）在多种特征配置下的系统实验，评估了数据集的实用性，结果显示XGB模型的F1得分达到98.34%。该数据集通过整合多类别的广泛特征，解决了类别不平衡、泛化性和可重复性等常见挑战，为钓鱼检测研究提供了可重用且一致的资源。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.17978

### 10. NWaaS: Nonintrusive Watermarking as a Service for X-to-Image DNN
#### Abstract:
The intellectual property of deep neural network (DNN) models can be protected with DNN watermarking, which embeds copyright watermarks into model parameters (white-box), model behavior (black-box), or model outputs (box-free), and the watermarks can be subsequently extracted to verify model ownership or detect model theft. Despite recent advances, these existing methods are inherently intrusive, as they either modify the model parameters or alter the structure. This natural intrusiveness raises concerns about watermarking-induced shifts in model behavior and the additional cost of fine-tuning, further exacerbated by the rapidly growing model size. As a result, model owners are often reluctant to adopt DNN watermarking in practice, which limits the development of practical Watermarking as a Service (WaaS) systems. To address this issue, we introduce Nonintrusive Watermarking as a Service (NWaaS), a novel trustless paradigm designed for X-to-Image models, in which we hypothesize that with the model untouched, an owner-defined watermark can still be extracted from model outputs. Building on this concept, we propose ShadowMark, a concrete implementation of NWaaS which addresses critical deployment challenges by establishing a robust and nonintrusive side channel in the protected model's black-box API, leveraging a key encoder and a watermark decoder. It is significantly distinctive from existing solutions by attaining the so-called absolute fidelity and being applicable to different DNN architectures, while being also robust against existing attacks, eliminating the fidelity-robustness trade-off. Extensive experiments on image-to-image, noise-to-image, noise-and-text-to-image, and text-to-image models, demonstrate the efficacy and practicality of ShadowMark for real-world deployment of nonintrusive DNN watermarking.
#### Summary:
这篇论文提出了一种名为NWaaS（Nonintrusive Watermarking as a Service）的新范式，旨在为X-to-Image深度学习模型提供非侵入式的水印服务。传统的DNN水印方法需要修改模型参数或结构，具有侵入性，可能影响模型行为并增加调优成本。NWaaS通过ShadowMark实现，在不修改模型的情况下，通过黑盒API建立稳健的侧信道，嵌入和提取水印，解决了现有方法在保真度和鲁棒性之间的权衡问题。实验表明，该方法适用于多种DNN架构，并能抵抗现有攻击。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18036

### 11. PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python
#### Abstract:
Python software development heavily relies on third-party packages. Direct and transitive dependencies create a labyrinth of software supply chains. While it is convenient to reuse code, vulnerabilities within these dependency chains can propagate through dependencies, potentially affecting down-stream packages and applications. PyPI, the official Python package repository, hosts many packages and lacks a comprehensive analysis of the prevalence of vulnerable dependencies. This paper introduces PyPitfall, a quantitative analysis of vulnerable dependencies across the PyPI ecosystem. We analyzed the dependency structures of 378,573 PyPI packages and identified 4,655 packages that explicitly require at least one known-vulnerable version and 141,044 packages that permit vulnerable versions within specified ranges. By characterizing the ecosystem-wide dependency landscape and the security impact of transitive dependencies, we aim to raise awareness of Python software supply chain security.
#### Summary:
这篇论文《PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python》主要研究了Python生态系统中第三方软件包的依赖关系及其带来的软件供应链漏洞问题。作者通过分析378,573个PyPI包，发现有4,655个包明确依赖已知漏洞版本，141,044个包允许在指定范围内使用有漏洞的版本。研究旨在揭示Python软件供应链的安全隐患，提高开发者对依赖链安全性的认识。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18075

### 12. LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models
#### Abstract:
Language Models (LMs) typically adhere to a "pre-training and fine-tuning" paradigm, where a universal pre-trained model can be fine-tuned to cater to various specialized domains. Low-Rank Adaptation (LoRA) has gained the most widespread use in LM fine-tuning due to its lightweight computational cost and remarkable performance. Because the proportion of parameters tuned by LoRA is relatively small, there might be a misleading impression that the LoRA fine-tuning data is invulnerable to Membership Inference Attacks (MIAs). However, we identify that utilizing the pre-trained model can induce more information leakage, which is neglected by existing MIAs. Therefore, we introduce LoRA-Leak, a holistic evaluation framework for MIAs against the fine-tuning datasets of LMs. LoRA-Leak incorporates fifteen membership inference attacks, including ten existing MIAs, and five improved MIAs that leverage the pre-trained model as a reference. In experiments, we apply LoRA-Leak to three advanced LMs across three popular natural language processing tasks, demonstrating that LoRA-based fine-tuned LMs are still vulnerable to MIAs (e.g., 0.775 AUC under conservative fine-tuning settings). We also applied LoRA-Leak to different fine-tuning settings to understand the resulting privacy risks. We further explore four defenses and find that only dropout and excluding specific LM layers during fine-tuning effectively mitigate MIA risks while maintaining utility. We highlight that under the "pre-training and fine-tuning" paradigm, the existence of the pre-trained model makes MIA a more severe risk for LoRA-based LMs. We hope that our findings can provide guidance on data privacy protection for specialized LM providers.
#### Summary:
这篇论文提出了LoRA-Leak，一个针对LoRA微调语言模型的成员推理攻击（MIA）评估框架。研究发现，尽管LoRA微调的参数比例较小，但利用预训练模型会导致更多信息泄露，使微调数据容易受到MIA攻击。论文通过实验验证了LoRA微调模型在多种自然语言处理任务中的脆弱性，并探讨了四种防御措施的有效性。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18302

### 13. Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment
#### Abstract:
With rapid advancement and increasing accessibility of LLMs, fine-tuning aligned models has become a critical step for adapting them to real-world applications, which makes the safety of this fine-tuning process more important than ever. However, recent studies have highlighted a critical challenge: even when fine-tuning with seemingly benign downstream datasets, the safety of aligned LLMs can be compromised, making them more susceptible to malicious instructions. In this paper, we show that fine-tuning datasets often contain samples with safety-degrading features that are not easily identifiable on the surface. These samples can significantly degrade the safety alignment of LLMs during fine-tuning. To address this issue, we propose LARF, a \textbf{L}ayer-\textbf{A}ware \textbf{R}epresentation \textbf{F}iltering method. This method identifies safety-sensitive layers within the LLM and leverages their representations to detect which data samples in the post-training dataset contain safety-degrading features. Experimental results demonstrate that LARF can effectively identify benign data with safety-degrading features. After removing such data, the safety alignment degradation caused by fine-tuning is mitigated. Please see our code at \href{this https URL}{this https URL}.
#### Summary:
这篇论文提出了LARF（Layer-Aware Representation Filtering）方法，用于在微调大型语言模型（LLM）时识别并过滤掉可能导致安全对齐退化的数据样本。研究发现，即使微调数据看似无害，也可能包含不易察觉的安全退化特征，这些特征会损害LLM的安全对齐。LARF通过识别LLM中的安全敏感层，并利用这些层的表示来检测数据中的安全退化特征，从而在微调前净化数据。实验证明，LARF能有效识别并移除这类数据，减轻微调导致的安全对齐退化。
#### Relevance Score: 6.0
#### PDF URL: https://arxiv.org/pdf/2507.18631

### 14. Agentic AI framework for End-to-End Medical Data Inference
#### Abstract:
Building and deploying machine learning solutions in healthcare remains expensive and labor-intensive due to fragmented preprocessing workflows, model compatibility issues, and stringent data privacy constraints. In this work, we introduce an Agentic AI framework that automates the entire clinical data pipeline, from ingestion to inference, through a system of modular, task-specific agents. These agents handle both structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing recommendation without manual intervention. We evaluate the system on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging. For example, in the case of structured data (anxiety data) and unstructured data (colonoscopy polyps data), the pipeline begins with file-type detection by the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring privacy compliance, where we first identify the data type and then anonymize it. The Feature Extraction Agent identifies features using an embedding-based approach for tabular data, extracting all column names, and a multi-stage MedGemma-based approach for image data, which infers modality and disease name. These features guide the Model-Data Feature Matcher Agent in selecting the best-fit model from a curated repository. The Preprocessing Recommender Agent and Preprocessing Implementor Agent then apply tailored preprocessing based on data type and model requirements. Finally, the ``Model Inference Agent" runs the selected model on the uploaded data and generates interpretable outputs using tools like SHAP, LIME, and DETR attention maps. By automating these high-friction stages of the ML lifecycle, the proposed framework reduces the need for repeated expert intervention, offering a scalable, cost-efficient pathway for operationalizing AI in clinical environments.
#### Summary:
这篇论文介绍了一个名为Agentic AI的框架，旨在自动化医疗数据从摄入到推理的整个流程。该框架通过一系列模块化、任务特定的代理来处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐，无需人工干预。论文评估了该系统在老年医学、姑息治疗和结肠镜成像等公开数据集上的表现，展示了其在减少专家干预、提高AI在临床环境中可操作性方面的潜力。
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.18115

### 15. Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios
#### Abstract:
Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step logic. In finance, however, professionals must not only converge on optimal decisions but also generate creative, plausible futures under uncertainty. We introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent thinking in LLMs for financial tasks.
ConDiFi features 607 macro-financial prompts for divergent reasoning and 990 multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we evaluated 14 leading models and uncovered striking differences. Despite high fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models like DeepSeek-R1 and Cohere Command R+ rank among the top for generating actionable, insights suitable for investment decisions. ConDiFi provides a new perspective to assess reasoning capabilities essential to safe and strategic deployment of LLMs in finance.
#### Summary:
这篇论文介绍了ConDiFi，一个用于评估大型语言模型（LLMs）在金融场景中发散和收敛思维能力的基准。ConDiFi包含607个宏观金融提示用于发散推理和990个多跳对抗性多选题用于收敛推理。研究评估了14个领先模型，发现GPT-4o在流畅性上表现优异，但在新颖性和可操作性上表现不佳，而DeepSeek-R1和Cohere Command R+在生成适合投资决策的可行见解方面表现突出。ConDiFi为评估LLMs在金融领域的安全和战略部署提供了新视角。
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.18368

### 16. AlphaGo Moment for Model Architecture Discovery
#### Abstract:
While AI systems demonstrate exponentially improving capabilities, the pace of AI research itself remains linearly bounded by human cognitive capacity, creating an increasingly severe development bottleneck. We present ASI-Arch, the first demonstration of Artificial Superintelligence for AI research (ASI4AI) in the critical domain of neural architecture discovery--a fully autonomous system that shatters this fundamental constraint by enabling AI to conduct its own architectural innovation. Moving beyond traditional Neural Architecture Search (NAS), which is fundamentally limited to exploring human-defined spaces, we introduce a paradigm shift from automated optimization to automated innovation. ASI-Arch can conduct end-to-end scientific research in the domain of architecture discovery, autonomously hypothesizing novel architectural concepts, implementing them as executable code, training and empirically validating their performance through rigorous experimentation and past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000 GPU hours, culminating in the discovery of 106 innovative, state-of-the-art (SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed unexpected strategic insights invisible to human players, our AI-discovered architectures demonstrate emergent design principles that systematically surpass human-designed baselines and illuminate previously unknown pathways for architectural innovation. Crucially, we establish the first empirical scaling law for scientific discovery itself--demonstrating that architectural breakthroughs can be scaled computationally, transforming research progress from a human-limited to a computation-scalable process. We provide comprehensive analysis of the emergent design patterns and autonomous research capabilities that enabled these breakthroughs, establishing a blueprint for self-accelerating AI systems.
#### Summary:
这篇论文介绍了ASI-Arch，一种用于神经网络架构发现的人工超级智能系统。它能够自主进行端到端的科学研究，包括提出新颖的架构概念、实现可执行代码、训练和验证性能。通过大量实验，ASI-Arch发现了106种创新的线性注意力架构，超越了人类设计的基准。论文还首次建立了科学发现本身的经验缩放定律，表明架构突破可以通过计算扩展，将研究进展从人类限制转变为可计算扩展的过程。
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.18074

### 17. Formal Verification of the Safegcd Implementation
#### Abstract:
The modular inverse is an essential piece of computation required for elliptic curve operations used for digital signatures in Bitcoin and other applications. A novel approach to the extended Euclidean algorithm has been developed by Bernstein and Yang within the last few years and incorporated into the libsecp256k1 cryptographic library used by Bitcoin. However, novel algorithms introduce new risks of errors. To address this we have completed a computer verified proof of the correctness of (one of) libsecp256k1's modular inverse implementations with the Coq proof assistant using the Verifiable C's implementation of separation logic.
#### Summary:
这篇论文主要介绍了对libsecp256k1加密库中模逆实现的形式化验证工作。作者使用Coq证明助手和Verifiable C的分离逻辑实现，验证了Bernstein和Yang提出的扩展欧几里得算法新实现的正确性，该算法用于比特币等应用中椭圆曲线操作的数字签名。
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.17956

### 18. Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering
#### Abstract:
The intellectual property of deep generative networks (GNets) can be protected using a cascaded hiding network (HNet) which embeds watermarks (or marks) into GNet outputs, known as box-free watermarking. Although both GNet and HNet are encapsulated in a black box (called operation network, or ONet), with only the generated and marked outputs from HNet being released to end users and deemed secure, in this paper, we reveal an overlooked vulnerability in such systems. Specifically, we show that the hidden GNet outputs can still be reliably estimated via query-based reverse engineering, leaking the generated and unmarked images, despite the attacker's limited knowledge of the system. Our first attempt is to reverse-engineer an inverse model for HNet under the stringent black-box condition, for which we propose to exploit the query process with specially curated input images. While effective, this method yields unsatisfactory image quality. To improve this, we subsequently propose an alternative method leveraging the equivalent additive property of box-free model watermarking and reverse-engineering a forward surrogate model of HNet, with better image quality preservation. Extensive experimental results on image processing and image generation tasks demonstrate that both attacks achieve impressive watermark removal success rates (100%) while also maintaining excellent image quality (reaching the highest PSNR of 34.69 dB), substantially outperforming existing attacks, highlighting the urgent need for robust defensive strategies to mitigate the identified vulnerability in box-free model watermarking.
#### Summary:
这篇论文揭示了深度学习生成网络（GNets）中盒式自由水印技术的安全漏洞。尽管生成网络和水印嵌入网络（HNet）被封装在黑盒中，仅发布带有水印的输出，但作者通过基于查询的反向工程方法，成功估计出未加水印的原始图像。论文提出了两种攻击方法：一种是反向工程HNet的逆模型，另一种是利用等效加法特性构建HNet的前向代理模型。实验表明，这两种方法都能100%成功去除水印，并保持较高的图像质量（PSNR最高达34.69 dB），突显了现有水印技术的脆弱性。
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.18034

### 19. An Improved ChaCha Algorithm Based on Quantum Random Number
#### Abstract:
Due to the merits of high efficiency and strong security against timing and side-channel attacks, ChaCha has been widely applied in real-time communication and data streaming scenarios. However, with the rapid development of AI-assisted cryptanalysis and quantum computing technologies, there are serious challenges to the secure implementation of ChaCha cipher. To further strengthen the security of ChaCha cipher, we propose an improved variant based on quantum random numbers, i.e., Quantum Random Number Enhanced ChaCha (QRE-ChaCha). Specifically, the design XORs the initial constants with quantum random numbers and periodically injects quantum random numbers into selected state words during odd rounds to enhance diffusion. Compared with the original ChaCha, the present variant shows stronger resistance to differential attacks and generates a keystream with statistical randomness, thereby offering increased robustness against both classical and quantum attacks. To evaluate the security and performance of the present ChaCha, our analysis proceeds in three main parts. Firstly, we analyze its theoretical security in terms of quantum randomness and attack testing, and conduct differential cryptanalysis with an automated search method based on the Boolean satisfiability problem (SAT). Secondly, we subject the keystream generated by the cipher to randomness tests using the NIST statistical test suite and the GM/T 0005-2021 randomness testing standard. Finally, we assess its encryption and decryption performance by measuring its encryption speed on files of various sizes. According to the results, the present ChaCha is significantly improved to resist differential attacks while maintaining the high efficiency of the original ChaCha cipher, and its keystream successfully passes statistical randomness tests using the NIST and GM/T 0005-2021 standards, meeting cryptographic application requirements.
#### Summary:
这篇论文提出了一种基于量子随机数的改进ChaCha算法（QRE-ChaCha），通过在初始常数中引入量子随机数并在奇数轮中定期注入量子随机数来增强扩散性。该算法在保持原始ChaCha高效性的同时，显著提高了对差分攻击的抵抗能力，并通过NIST和GM/T 0005-2021标准的随机性测试，验证了其安全性和适用性。
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.18157

### 20. Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models
#### Abstract:
Digitalization of power grids have made them increasingly susceptible to cyber-attacks in the past decade. Iterative cybersecurity testing is indispensable to counter emerging attack vectors and to ensure dependability of critical infrastructure. Furthermore, these can be used to evaluate cybersecurity configuration, effectiveness of the cybersecurity measures against various attack vectors, as well as to train smart grid cybersecurity experts defending the system. Enabling extensive experiments narrows the gap between academic research and production environment. A high-fidelity cyber range is vital as it is often infeasible to conduct such experiments and training using production environment. However, the design and implementation of cyber range requires extensive domain knowledge of physical and cyber aspect of the infrastructure. Furthermore, costs incurred for setup and maintenance of cyber range are significant. Moreover, most existing smart grid cyber ranges are designed as a one-off, proprietary system, and are limited in terms of configurability, accessibility, portability, and reproducibility. To address these challenges, an automated Smart grid Cyber Range generation framework is presented in this paper. Initially a human-/machine-friendly, XML-based modeling language called Smart Grid Modeling Language was defined, which incorporates IEC 61850 System Configuration Language files. Subsequently, a toolchain to parse SG-ML model files and automatically instantiate a functional smart grid cyber range was developed. The developed SG-ML models can be easily shared and/or modified to reproduce or customize for any cyber range. The application of Auto-SGCR is demonstrated through case studies with large-scale substation models. The toolchain along with example SG-ML models have been open-sourced.
#### Summary:
这篇论文提出了一个名为Auto-SGCR的自动化框架，用于生成智能电网网络靶场（Cyber Range）。该框架通过定义一种基于XML的建模语言（SG-ML），并结合IEC 61850系统配置语言文件，实现了智能电网网络靶场的自动化和可配置化。论文还开发了一个工具链，用于解析SG-ML模型文件并自动实例化功能性的智能电网网络靶场。通过案例研究展示了Auto-SGCR在大规模变电站模型中的应用，并将工具链和示例SG-ML模型开源。
#### Relevance Score: 5.0
#### PDF URL: https://arxiv.org/pdf/2507.18249

### 21. Multi-Agent Guided Policy Optimization
#### Abstract:
Due to practical constraints such as partial observability and limited communication, Centralized Training with Decentralized Execution (CTDE) has become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning (MARL). However, existing CTDE methods often underutilize centralized training or lack theoretical guarantees. We propose Multi-Agent Guided Policy Optimization (MAGPO), a novel framework that better leverages centralized training by integrating centralized guidance with decentralized execution. MAGPO uses an auto-regressive joint policy for scalable, coordinated exploration and explicitly aligns it with decentralized policies to ensure deployability under partial observability. We provide theoretical guarantees of monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across 6 diverse environments. Results show that MAGPO consistently outperforms strong CTDE baselines and matches or surpasses fully centralized approaches, offering a principled and practical solution for decentralized multi-agent learning. Our code and experimental data can be found in this https URL.
#### Summary:
这篇论文提出了一种名为多智能体引导策略优化（MAGPO）的新框架，用于改进合作型多智能体强化学习（MARL）中的集中训练分散执行（CTDE）范式。MAGPO通过整合集中引导与分散执行，更好地利用集中训练，同时确保在部分可观测条件下的可部署性。论文提供了单调策略改进的理论保证，并在6个不同环境的43个任务上进行了实验评估，结果表明MAGPO consistently outperforms strong CTDE baselines and matches or surpasses fully centralized approaches。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18059

### 22. E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI
#### Abstract:
How can AI move beyond imitation toward genuine creativity? This paper proposes the E.A.R.T.H. framework, a five-stage generative pipeline that transforms model-generated errors into creative assets through Error generation, Amplification, Refine selection, Transform, and Harness feedback. Drawing on cognitive science and generative modeling, we posit that "creative potential hides in failure" and operationalize this via structured prompts, semantic scoring, and human-in-the-loop evaluation. Implemented using LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the pipeline employs a composite reward function based on novelty, surprise, and relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to 1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4% improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a 4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment (CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones (3.99). Feedback highlights stylistic precision and emotional resonance. These results demonstrate that error-centered, feedback-driven generation enhances creativity, offering a scalable path toward self-evolving, human-aligned creative AI.
#### Summary:
这篇论文提出了E.A.R.T.H.框架，一个五阶段的生成流程，通过错误生成、放大、精炼选择、转换和利用反馈，将模型生成的错误转化为创意资产。该框架结合了认知科学和生成模型，认为“创意潜力隐藏在失败中”，并通过结构化提示、语义评分和人类参与评估来实现。实验结果显示，该框架显著提高了创意评分，并在跨模态测试中表现出色。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.18004

### 23. Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment
#### Abstract:
The deployment of large-scale software-based 5G core functions presents significant challenges due to their reliance on optimized and intelligent resource provisioning for their services. Many studies have focused on analyzing the impact of resource allocation for complex deployments using mathematical models, queue theories, or even Artificial Intelligence (AI). This paper elucidates the effects of chaotic workloads, generated by Distributed Denial of Service (DDoS) on different Network Functions (NFs) on User Equipment registration performance. Our findings highlight the necessity of diverse resource profiles to ensure Service-Level Agreement (SLA) compliance in large-scale 5G core deployments. Additionally, our analysis of packet capture approaches demonstrates the potential of kernel-based monitoring for scalable security threat defense. Finally, our empirical evaluation provides insights into the effective deployment of 5G NFs in complex scenarios.
#### Summary:
这篇论文探讨了大规模基于软件的5G核心功能部署中的性能评估和威胁缓解问题。研究重点分析了分布式拒绝服务（DDoS）攻击产生的混沌工作负载对不同网络功能（NFs）在用户设备注册性能上的影响，并强调了多样化资源配给对确保服务级别协议（SLA）合规性的重要性。此外，论文还评估了基于内核的监控方法在可扩展安全威胁防御中的潜力，并提供了在复杂场景中有效部署5G NFs的实证见解。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.17850

### 24. TimelyHLS: LLM-Based Timing-Aware and Architecture-Specific FPGA HLS Optimization
#### Abstract:
Achieving timing closure and design-specific optimizations in FPGA-targeted High-Level Synthesis (HLS) remains a significant challenge due to the complex interaction between architectural constraints, resource utilization, and the absence of automated support for platform-specific pragmas. In this work, we propose TimelyHLS, a novel framework integrating Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) to automatically generate and iteratively refine HLS code optimized for FPGA-specific timing and performance requirements. TimelyHLS is driven by a structured architectural knowledge base containing FPGA-specific features, synthesis directives, and pragma templates. Given a kernel, TimelyHLS generates HLS code annotated with both timing-critical and design-specific pragmas. The synthesized RTL is then evaluated using commercial toolchains, and simulation correctness is verified against reference outputs via custom testbenches. TimelyHLS iteratively incorporates synthesis logs and performance reports into the LLM engine for refinement in the presence of functional discrepancies. Experimental results across 10 FPGA architectures and diverse benchmarks show that TimelyHLS reduces the need for manual tuning by up to 70%, while achieving up to 4x latency speedup (e.g., 3.85x for Matrix Multiplication, 3.7x for Bitonic Sort) and over 50% area savings in certain cases (e.g., 57% FF reduction in Viterbi). TimelyHLS consistently achieves timing closure and functional correctness across platforms, highlighting the effectiveness of LLM-driven, architecture-aware synthesis in automating FPGA design.
#### Summary:
这篇论文提出了TimelyHLS，一个结合大型语言模型（LLMs）和检索增强生成（RAG）的新框架，用于自动生成和迭代优化针对FPGA特定时序和性能需求的高层次综合（HLS）代码。TimelyHLS通过结构化的架构知识库驱动，生成带有时序关键和设计特定pragma注释的HLS代码，并通过商业工具链评估生成的RTL，验证其功能正确性。实验结果表明，TimelyHLS在多种FPGA架构和基准测试中显著减少了手动调优的需求，同时实现了显著的性能提升和资源节省。
#### Relevance Score: 4.0
#### PDF URL: https://arxiv.org/pdf/2507.17962

### 25. Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes
#### Abstract:
The rapid development of COVID-19 vaccines has showcased the global communitys ability to combat infectious diseases. However, the need for post-licensure surveillance systems has grown due to the limited window for safety data collection in clinical trials and early widespread implementation. This study aims to employ Natural Language Processing techniques and Active Learning to rapidly develop a classifier that detects potential vaccine safety issues from emergency department notes. ED triage notes, containing expert, succinct vital patient information at the point of entry to health systems, can significantly contribute to timely vaccine safety signal surveillance. While keyword-based classification can be effective, it may yield false positives and demand extensive keyword modifications. This is exacerbated by the infrequency of vaccination-related ED presentations and their similarity to other reasons for ED visits. NLP offers a more accurate and efficient alternative, albeit requiring annotated data, which is often scarce in the medical field. Active learning optimizes the annotation process and the quality of annotated data, which can result in faster model implementation and improved model performance. This work combines active learning, data augmentation, and active learning and evaluation techniques to create a classifier that is used to enhance vaccine safety surveillance from ED triage notes.
#### Summary:
这篇论文探讨了如何利用自然语言处理（NLP）技术和主动学习（Active Learning）从急诊分诊笔记中快速开发一个分类器，以检测潜在的疫苗安全问题。由于临床试验和早期广泛实施中安全数据收集的时间有限，疫苗上市后的监测系统变得尤为重要。论文提出了一种结合主动学习、数据增强和评估技术的方法，以提高疫苗安全监测的效率和准确性。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18123

### 26. The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams
#### Abstract:
We present our method for automatically marking Physics exams. The marking problem consists in assessing typed student answers for correctness with respect to a ground truth solution. This is a challenging problem that we seek to tackle using a combination of a computer algebra system, an SMT solver and a term rewriting system. A Large Language Model is used to interpret and remove errors from student responses and rewrite these in a machine readable format. Once formalized and language-aligned, the next step then consists in applying automated reasoning techniques for assessing student solution correctness. We consider two methods of automated theorem proving: off-the-shelf SMT solving and term rewriting systems tailored for physics problems involving trigonometric expressions. The development of the term rewrite system and establishing termination and confluence properties was not trivial, and we describe it in some detail in the paper. We evaluate our system on a rich pool of over 1500 real-world student exam responses from the 2023 Australian Physics Olympiad.
#### Summary:
这篇论文介绍了一种自动批改物理考试的方法，结合了计算机代数系统、SMT求解器和项重写系统。利用大型语言模型（LLM）解释和纠正学生答案，并将其转换为机器可读格式。随后，通过自动推理技术评估答案的正确性，重点讨论了针对涉及三角表达式的物理问题定制的项重写系统的开发及其终止性和合流性。系统在2023年澳大利亚物理奥林匹克竞赛的1500多份学生答卷上进行了评估。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18337

### 27. SMARTAPS: Tool-augmented LLMs for Operations Management
#### Abstract:
Large language models (LLMs) present intriguing opportunities to enhance user interaction with traditional algorithms and tools in real-world applications. An advanced planning system (APS) is a sophisticated software that leverages optimization to help operations planners create, interpret, and modify an operational plan. While highly beneficial, many customers are priced out of using an APS due to the ongoing costs of consultants responsible for customization and maintenance. To address the need for a more accessible APS expressed by supply chain planners, we present SmartAPS, a conversational system built on a tool-augmented LLM. Our system provides operations planners with an intuitive natural language chat interface, allowing them to query information, perform counterfactual reasoning, receive recommendations, and execute scenario analysis to better manage their operation. A short video demonstrating the system has been released: this https URL
#### Summary:
这篇论文介绍了SmartAPS，一个基于工具增强的大型语言模型（LLM）的对话系统，旨在为运营规划者提供一个直观的自然语言聊天界面。该系统允许用户查询信息、进行反事实推理、接收建议和执行场景分析，以更好地管理其运营。论文的目标是解决由于定制和维护成本高昂而导致许多客户无法使用高级规划系统（APS）的问题。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.17927

### 28. Does visualization help AI understand data?
#### Abstract:
Charts and graphs help people analyze data, but can they also be useful to AI systems? To investigate this question, we perform a series of experiments with two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three representative analysis tasks, the two systems describe synthetic datasets more precisely and accurately when raw data is accompanied by a scatterplot, especially as datasets grow in complexity. Comparison with two baselines -- providing a blank chart and a chart with mismatched data -- shows that the improved performance is due to the content of the charts. Our results are initial evidence that AI systems, like humans, can benefit from visualization.
#### Summary:
这篇论文探讨了可视化是否有助于AI系统理解数据。通过实验，研究发现商业视觉语言模型（如GPT 4.1和Claude 3.5）在分析任务中，当原始数据伴随散点图时，能够更精确和准确地描述合成数据集，尤其是在数据集复杂度增加时。与空白图表或数据不匹配的图表相比，性能提升归因于图表内容。结果表明，AI系统可能像人类一样从可视化中受益。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18022

### 29. Foundations for Risk Assessment of AI in Protecting Fundamental Rights
#### Abstract:
This chapter introduces a conceptual framework for qualitative risk assessment of AI, particularly in the context of the EU AI Act. The framework addresses the complexities of legal compliance and fundamental rights protection by itegrating definitional balancing and defeasible reasoning. Definitional balancing employs proportionality analysis to resolve conflicts between competing rights, while defeasible reasoning accommodates the dynamic nature of legal decision-making. Our approach stresses the need for an analysis of AI deployment scenarios and for identifying potential legal violations and multi-layered impacts on fundamental rights. On the basis of this analysis, we provide philosophical foundations for a logical account of AI risk analysis. In particular, we consider the basic building blocks for conceptually grasping the interaction between AI deployment scenarios and fundamental rights, incorporating in defeasible reasoning definitional balancing and arguments about the contextual promotion or demotion of rights. This layered approach allows for more operative models of assessment of both high-risk AI systems and General Purpose AI (GPAI) systems, emphasizing the broader applicability of the latter. Future work aims to develop a formal model and effective algorithms to enhance AI risk assessment, bridging theoretical insights with practical applications to support responsible AI governance.
#### Summary:
本章介绍了一个用于AI定性风险评估的概念框架，特别是在欧盟AI法案的背景下。该框架通过整合定义性平衡和可废止推理，解决了法律合规性和基本权利保护的复杂性。定义性平衡采用比例分析来解决竞争权利之间的冲突，而可废止推理则适应法律决策的动态性。该方法强调分析AI部署场景、识别潜在法律违规行为以及对基本权利的多层次影响。在此基础上，提供了AI风险分析的哲学基础，特别是理解AI部署场景与基本权利之间相互作用的基本构建块。未来工作旨在开发正式模型和有效算法，以增强AI风险评估，将理论见解与实际应用相结合，支持负责任的AI治理。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18290

### 30. Logical Characterizations of GNNs with Mean Aggregation
#### Abstract:
We study the expressive power of graph neural networks (GNNs) with mean as the aggregation function. In the non-uniform setting, we show that such GNNs have exactly the same expressive power as ratio modal logic, which has modal operators expressing that at least a certain ratio of the successors of a vertex satisfies a specified property. The non-uniform expressive power of mean GNNs is thus higher than that of GNNs with max aggregation, but lower than for sum aggregation--the latter are characterized by modal logic and graded modal logic, respectively. In the uniform setting, we show that the expressive power relative to MSO is exactly that of alternation-free modal logic, under the natural assumptions that combination functions are continuous and classification functions are thresholds. This implies that, relative to MSO and in the uniform setting, mean GNNs are strictly less expressive than sum GNNs and max GNNs. When any of the assumptions is dropped, the expressive power increases.
#### Summary:
这篇论文研究了使用均值聚合的图神经网络（GNNs）的表达能力。在非均匀设置下，这类GNNs的表达能力等同于比率模态逻辑，其模态运算符能够表达顶点后继中满足特定属性的比例。与使用最大聚合的GNNs相比，均值GNNs的表达能力更高，但低于使用求和聚合的GNNs。在均匀设置下，论文表明，在组合函数连续且分类函数为阈值的自然假设下，均值GNNs相对于MSO的表达能力等同于无交替模态逻辑。这意味着，相对于MSO且在均匀设置下，均值GNNs的表达能力严格低于求和GNNs和最大GNNs。如果放弃这些假设，表达能力会增强。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18145

### 31. On the Performance of Concept Probing: The Influence of the Data (Extended Version)
#### Abstract:
Concept probing has recently garnered increasing interest as a way to help interpret artificial neural networks, dealing both with their typically large size and their subsymbolic nature, which ultimately renders them unfeasible for direct human interpretation. Concept probing works by training additional classifiers to map the internal representations of a model into human-defined concepts of interest, thus allowing humans to peek inside artificial neural networks. Research on concept probing has mainly focused on the model being probed or the probing model itself, paying limited attention to the data required to train such probing models. In this paper, we address this gap. Focusing on concept probing in the context of image classification tasks, we investigate the effect of the data used to train probing models on their performance. We also make available concept labels for two widely used datasets.
#### Summary:
这篇论文研究了概念探测（concept probing）在人工神经网络解释中的应用，特别是探讨了用于训练探测模型的数据对其性能的影响。作者关注图像分类任务中的概念探测，并分析了不同数据对探测模型效果的作用，同时公开了两个广泛使用数据集的概念标签。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18550

### 32. Digital Twin Technologies in Predictive Maintenance: Enabling Transferability via Sim-to-Real and Real-to-Sim Transfer
#### Abstract:
The advancement of the Internet of Things (IoT) and Artificial Intelligence has catalyzed the evolution of Digital Twins (DTs) from conceptual ideas to more implementable realities. Yet, transitioning from academia to industry is complex due to the absence of standardized frameworks. This paper builds upon the authors' previously established functional and informational requirements supporting standardized DT development, focusing on a crucial aspect: transferability. While existing DT research primarily centers on asset transfer, the significance of "sim-to-real transfer" and "real-to-sim transfer"--transferring knowledge between simulations and real-world operations--is vital for comprehensive lifecycle management in DTs. A key challenge in this process is calibrating the "reality gap," the discrepancy between simulated predictions and actual outcomes. Our research investigates the impact of integrating a single Reality Gap Analysis (RGA) module into an existing DT framework to effectively manage both sim-to-real and real-to-sim transfers. This integration is facilitated by data pipelines that connect the RGA module with the existing components of the DT framework, including the historical repository and the simulation model. A case study on a pedestrian bridge at Carnegie Mellon University showcases the performance of different levels of integration of our approach with an existing framework. With full implementation of an RGA module and a complete data pipeline, our approach is capable of bidirectional knowledge transfer between simulations and real-world operations without compromising efficiency.
#### Summary:
这篇论文探讨了数字孪生（DT）技术在预测性维护中的应用，特别是通过“模拟到现实”（sim-to-real）和“现实到模拟”（real-to-sim）转移实现知识转移的重要性。作者提出了一个现实差距分析（RGA）模块，用于校准模拟预测与实际结果之间的差异，并通过数据管道将其集成到现有DT框架中。论文以卡内基梅隆大学的一座人行桥为例，展示了该方法在不同集成水平下的性能表现。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18449

### 33. Conformidade com os Requisitos Legais de Privacidade de Dados: Um Estudo sobre Técnicas de Anonimização
#### Abstract:
The protection of personal data has become a central topic in software development, especially with the implementation of the General Data Protection Law (LGPD) in Brazil and the General Data Protection Regulation (GDPR) in the European Union. With the enforcement of these laws, certain software quality criteria have become mandatory, such as data anonymization, which is one of the main aspects addressed by these regulations. The aim of this article is to analyze data anonymization techniques and assess their effectiveness in ensuring compliance with legal requirements and the utility of the data for its intended purpose. Techniques such as aggregation, generalization, perturbation, and k-anonymity were investigated and applied to datasets containing personal and sensitive data. The analysis revealed significant variations in the effectiveness of each method, highlighting the need to balance privacy and data utility.
#### Summary:
这篇论文研究了数据隐私保护中的匿名化技术，特别是在巴西的LGPD和欧盟的GDPR法规实施背景下。文章分析了聚合、泛化、扰动和k-匿名等匿名化技术的有效性，并探讨了如何在确保隐私的同时保持数据的实用性。研究发现不同方法的有效性存在显著差异，强调了平衡隐私与数据效用的重要性。
#### Relevance Score: 3.0
#### PDF URL: https://arxiv.org/pdf/2507.18360

### 34. ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics
#### Abstract:
Unlike conventional Machine-Learning (ML) approaches, often criticized as "black boxes", Symbolic Regression (SR) stands out as a powerful tool for revealing interpretable mathematical relationships in complex physical systems, requiring no a priori assumptions about models' structures. Motivated by the recognition that, in fluid mechanics, an understanding of the underlying flow physics is as crucial as accurate prediction, this study applies SR to model a fundamental three-dimensional (3D) incompressible flow in a rectangular channel, focusing on the (axial) velocity and pressure fields under laminar conditions. By employing the PySR library, compact symbolic equations were derived directly from numerical simulation data, revealing key characteristics of the flow dynamics. These equations not only approximate the parabolic velocity profile and pressure drop observed in the studied fluid flow, but also perfectly coincide with analytical solutions from the literature. Furthermore, we propose an innovative approach that integrates SR with the knowledge-representation framework of Answer Set Programming (ASP), combining the generative power of SR with the declarative reasoning strengths of ASP. The proposed hybrid SR/ASP framework ensures that the SR-generated symbolic expressions are not only statistically accurate, but also physically plausible, adhering to domain-specific principles. Overall, the study highlights two key contributions: SR's ability to simplify complex flow behaviours into concise, interpretable equations, and the potential of knowledge-representation approaches to improve the reliability and alignment of data-driven SR models with domain principles. Insights from the examined 3D channel flow pave the way for integrating such hybrid approaches into efficient frameworks, [...] where explainable predictions and real-time data analysis are crucial.
#### Summary:
该论文提出了一种结合符号回归（SR）和答案集编程（ASP）的混合方法，用于从流体力学数值模拟数据中推导出可解释的数学关系。研究通过PySR库直接从数据中生成紧凑的符号方程，揭示了流体动力学中的关键特征，并与文献中的解析解完美吻合。此外，论文还展示了SR与ASP结合的优势，确保生成的符号表达式不仅统计准确，而且物理上合理，符合领域特定原则。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.17777

### 35. Synthesis of timeline-based planning strategies avoiding determinization
#### Abstract:
Qualitative timeline-based planning models domains as sets of independent, but
interacting, components whose behaviors over time, the timelines, are governed
by sets of qualitative temporal constraints (ordering relations), called
synchronization rules.
Its plan-existence problem has been shown to be PSPACE-complete; in
particular, PSPACE-membership has been proved via reduction to the
nonemptiness problem for nondeterministic finite automata.
However, nondeterministic automata cannot be directly used to synthesize
planning strategies as a costly determinization step is needed.
In this paper, we identify a fragment of qualitative timeline-based planning
whose plan-existence problem can be directly mapped into the nonemptiness
problem of deterministic finite automata, which can then
synthesize strategies.
In addition, we identify a maximal subset of Allen's relations that fits into
such a deterministic fragment.
#### Summary:
这篇论文研究了基于时间线的定性规划问题，提出了一种避免确定性化的规划策略合成方法。作者识别了一个特定的规划片段，其规划存在性问题可以直接映射到确定性有限自动机的非空性问题，从而能够直接合成策略。此外，论文还确定了Allen关系的一个最大子集，适用于这种确定性片段。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.17988

### 36. Comparing Non-minimal Semantics for Disjunction in Answer Set Programming
#### Abstract:
In this paper, we compare four different semantics for disjunction in Answer Set Programming that, unlike stable models, do not adhere to the principle of model minimality. Two of these approaches, Cabalar and Muñiz' \emph{Justified Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly provide an alternative non-minimal semantics for disjunction. The other two, Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference} (DI) semantics, actually introduce a new disjunction connective, but are compared here as if they constituted new semantics for the standard disjunction operator. We are able to prove that three of these approaches (Forks, Justified Models and a reasonable relaxation of the DI semantics) actually coincide, constituting a common single approach under different definitions. Moreover, this common semantics always provides a superset of the stable models of a program (in fact, modulo any context) and is strictly stronger than the fourth approach (Strongly Supported Models), that actually treats disjunctions as in classical logic.
#### Summary:
本文比较了答案集编程（Answer Set Programming）中四种不同的非极小语义处理析取的方法。这些方法不遵循模型极小性原则，包括Cabalar和Muñiz的“Justified Models”、Doherty和Szalas的“Strongly Supported Models”、Aguado等人的“Forks”以及Shen和Eiter的“Determining Inference”（DI）语义。研究发现，其中三种方法（Forks、Justified Models和DI语义的合理松弛）实际上是一致的，构成了一个共同的方法，并且总是提供程序稳定模型的超集。而第四种方法（Strongly Supported Models）则较弱，将析取视为经典逻辑中的处理方式。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18198

### 37. GPU Accelerated Compact-Table Propagation
#### Abstract:
Constraint Programming developed within Logic Programming in the Eighties; nowadays all Prolog systems encompass modules capable of handling constraint programming on finite domains demanding their solution to a constraint solver. This work focuses on a specific form of constraint, the so-called table constraint, used to specify conditions on the values of variables as an enumeration of alternative options. Since every condition on a set of finite domain variables can be ultimately expressed as a finite set of cases, Table can, in principle, simulate any other constraint. These characteristics make Table one of the most studied constraints ever, leading to a series of increasingly efficient propagation algorithms. Despite this, it is not uncommon to encounter real-world problems with hundreds or thousands of valid cases that are simply too many to be handled effectively with standard CPU-based approaches. In this paper, we deal with the Compact-Table (CT) algorithm, the state-of-the-art propagation algorithms for Table. We describe how CT can be enhanced by exploiting the massive computational power offered by modern GPUs to handle large Table constraints. In particular, we report on the design and implementation of GPU-accelerated CT, on its integration into an existing constraint solver, and on an experimental validation performed on a significant set of instances.
#### Summary:
这篇论文主要研究了一种名为Compact-Table（CT）的约束传播算法，该算法用于处理表约束（table constraint），即通过枚举变量的可能值来指定条件。作者提出了一种利用现代GPU的大规模计算能力来加速CT算法的方法，以处理现实世界中包含大量有效案例的问题。论文详细描述了GPU加速CT算法的设计、实现及其在现有约束求解器中的集成，并通过实验验证了其有效性。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18413

### 38. Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation
#### Abstract:
This paper investigates the application of Reinforcement Learning (RL) to optimise call routing in call centres to minimise client waiting time and staff idle time. Two methods are compared: a model-based approach using Value Iteration (VI) under known system dynamics, and a model-free approach using Proximal Policy Optimisation (PPO) that learns from experience. For the model-based approach, a theoretical model is used, while a simulation model combining Discrete Event Simulation (DES) with the OpenAI Gym environment is developed for model-free learning. Both models frame the problem as a Markov Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with Poisson client arrivals and exponentially distributed service and abandonment times. For policy evaluation, random, VI, and PPO policies are evaluated using the simulation model. After 1,000 test episodes, PPO consistently achives the highest rewards, along with the lowest client waiting time and staff idle time, despite requiring longer training time.
#### Summary:
这篇论文研究了在呼叫中心中使用强化学习（RL）来优化呼叫路由，以减少客户等待时间和员工空闲时间。研究比较了两种方法：基于模型的价值迭代（VI）和无模型的近端策略优化（PPO）。VI在已知系统动态的情况下使用理论模型，而PPO通过结合离散事件模拟（DES）和OpenAI Gym环境的模拟模型从经验中学习。两种方法都将问题建模为基于技能路由（SBR）框架下的马尔可夫决策过程（MDP）。经过1,000次测试后，PPO在奖励、客户等待时间和员工空闲时间方面表现最佳，尽管需要更长的训练时间。
#### Relevance Score: 2.0
#### PDF URL: https://arxiv.org/pdf/2507.18398

